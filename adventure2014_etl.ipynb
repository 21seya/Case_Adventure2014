{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2cd2fb-112f-4c2f-baa2-9a2d96af0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando spark sessão \n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import current_date\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# criando a sessão\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"/Ubuntu/home/wallace/hadoop/spark-3.5.1/jars/postgresql-42.7.3.jar\")\\\n",
    "                            .master(\"local\")\\\n",
    "                            .appName(\"PySpark_Postgres_test\")\\\n",
    "                            .getOrCreate()\n",
    "\n",
    "df_pessoa = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"person.person\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d955c0cf-48ef-46d1-afdf-6b22aaf5e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- businessentityid: integer (nullable = true)\n",
      " |-- persontype: string (nullable = true)\n",
      " |-- namestyle: boolean (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- suffix: string (nullable = true)\n",
      " |-- emailpromotion: integer (nullable = true)\n",
      " |-- additionalcontactinfo: string (nullable = true)\n",
      " |-- demographics: string (nullable = true)\n",
      " |-- rowguid: string (nullable = true)\n",
      " |-- modifieddate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pessoa.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ada67139-faf0-4758-8c25-63249c64360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:36:14 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 23:36:14 INFO DAGScheduler: Got job 71 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:36:14 INFO DAGScheduler: Final stage: ResultStage 91 (showString at <unknown>:0)\n",
      "24/08/19 23:36:14 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:36:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:36:14 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[200] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:36:14 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)\n",
      "24/08/19 23:36:15 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)\n",
      "24/08/19 23:36:15 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:36:15 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:36:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[200] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:36:15 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:36:15 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 71) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:36:15 INFO Executor: Running task 0.0 in stage 91.0 (TID 71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "|businessentityid|persontype|namestyle|title|firstname|middlename|  lastname|suffix|emailpromotion|additionalcontactinfo|        demographics|             rowguid|       modifieddate|\n",
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "|               1|        EM|    false| NULL|      Ken|         J|   Sánchez|  NULL|             0|                 NULL|<IndividualSurvey...|92c4279f-1207-48a...|2009-01-07 00:00:00|\n",
      "|               2|        EM|    false| NULL|    Terri|       Lee|     Duffy|  NULL|             1|                 NULL|<IndividualSurvey...|d8763459-8aa8-47c...|2008-01-24 00:00:00|\n",
      "|               3|        EM|    false| NULL|  Roberto|      NULL|Tamburello|  NULL|             0|                 NULL|<IndividualSurvey...|e1a2555e-0828-434...|2007-11-04 00:00:00|\n",
      "|               4|        EM|    false| NULL|      Rob|      NULL|   Walters|  NULL|             0|                 NULL|<IndividualSurvey...|f2d7ce06-38b3-435...|2007-11-28 00:00:00|\n",
      "|               5|        EM|    false|  Ms.|     Gail|         A|  Erickson|  NULL|             0|                 NULL|<IndividualSurvey...|f3a3f6b4-ae3b-430...|2007-12-30 00:00:00|\n",
      "|               6|        EM|    false|  Mr.|   Jossef|         H|  Goldberg|  NULL|             0|                 NULL|<IndividualSurvey...|0dea28fd-effe-482...|2013-12-16 00:00:00|\n",
      "|               7|        EM|    false| NULL|    Dylan|         A|    Miller|  NULL|             2|                 NULL|<IndividualSurvey...|c45e8ab8-01be-4b7...|2009-02-01 00:00:00|\n",
      "|               8|        EM|    false| NULL|    Diane|         L|  Margheim|  NULL|             0|                 NULL|<IndividualSurvey...|a948e590-4a56-45a...|2008-12-22 00:00:00|\n",
      "|               9|        EM|    false| NULL|     Gigi|         N|   Matthew|  NULL|             0|                 NULL|<IndividualSurvey...|5fc28c0e-6d36-425...|2009-01-09 00:00:00|\n",
      "|              10|        EM|    false| NULL|  Michael|      NULL|    Raheem|  NULL|             2|                 NULL|<IndividualSurvey...|ca2c740e-75b2-420...|2009-04-26 00:00:00|\n",
      "|              11|        EM|    false| NULL|   Ovidiu|         V|   Cracium|  NULL|             0|                 NULL|<IndividualSurvey...|d2cc2577-ef6b-440...|2010-11-28 00:00:00|\n",
      "|              12|        EM|    false| NULL|  Thierry|         B|    D'Hers|  NULL|             2|                 NULL|<IndividualSurvey...|fa263c7f-600d-4e8...|2007-12-04 00:00:00|\n",
      "|              13|        EM|    false|  Ms.|   Janice|         M|    Galvin|  NULL|             2|                 NULL|<IndividualSurvey...|34eb99e0-7042-4dc...|2010-12-16 00:00:00|\n",
      "|              14|        EM|    false| NULL|  Michael|         I|  Sullivan|  NULL|             2|                 NULL|<IndividualSurvey...|9a7501de-5caf-470...|2010-12-23 00:00:00|\n",
      "|              15|        EM|    false| NULL|   Sharon|         B| Salavaria|  NULL|             2|                 NULL|<IndividualSurvey...|beba63cb-13f1-4b7...|2011-01-11 00:00:00|\n",
      "|              16|        EM|    false| NULL|    David|         M|   Bradley|  NULL|             1|                 NULL|<IndividualSurvey...|2cc8ba72-5dbb-497...|2007-12-13 00:00:00|\n",
      "|              17|        EM|    false| NULL|    Kevin|         F|     Brown|  NULL|             2|                 NULL|<IndividualSurvey...|9ee4713e-b3d8-440...|2007-01-19 00:00:00|\n",
      "|              18|        EM|    false| NULL|     John|         L|      Wood|  NULL|             2|                 NULL|<IndividualSurvey...|fe21bda7-9327-4d1...|2011-01-31 00:00:00|\n",
      "|              19|        EM|    false| NULL|     Mary|         A|   Dempsey|  NULL|             1|                 NULL|<IndividualSurvey...|36f04305-6769-4e6...|2011-02-07 00:00:00|\n",
      "|              20|        EM|    false| NULL|   Wanida|         M|  Benshoof|  NULL|             2|                 NULL|<IndividualSurvey...|1e7e56f4-a583-4e3...|2010-12-31 00:00:00|\n",
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:36:15 INFO JDBCRDD: closed connection                   (0 + 1) / 1]\n",
      "24/08/19 23:36:15 INFO Executor: Finished task 0.0 in stage 91.0 (TID 71). 3979 bytes result sent to driver\n",
      "24/08/19 23:36:15 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 71) in 197 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:36:15 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:36:15 INFO DAGScheduler: ResultStage 91 (showString at <unknown>:0) finished in 0.813 s\n",
      "24/08/19 23:36:15 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:36:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "24/08/19 23:36:15 INFO DAGScheduler: Job 71 finished: showString at <unknown>:0, took 0.822298 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pessoa.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "37551787-700b-4c49-b924-fe52f019ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:37:42 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:37:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:37:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:37:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:37:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:37:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:37:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:37:42 INFO CodeGenerator: Code generated in 146.615599 ms\n",
      "24/08/19 23:37:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Got job 72 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Final stage: ResultStage 92 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[203] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:37:42 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 219.5 KiB, free 434.2 MiB)\n",
      "24/08/19 23:37:42 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 434.1 MiB)\n",
      "24/08/19 23:37:42 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.255.255.254:36873 (size: 78.8 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:37:42 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[203] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:37:42 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:37:42 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 72) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:37:42 INFO Executor: Running task 0.0 in stage 92.0 (TID 72)\n",
      "24/08/19 23:37:43 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:37:43 INFO CodeGenerator: Code generated in 7.7618 ms\n",
      "24/08/19 23:37:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:37:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:37:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:37:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:37:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:37:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:37:43 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:37:43 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:37:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:37:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"persontype\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"namestyle\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"title\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(8)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"firstname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"middlename\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"lastname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"suffix\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(10)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"emailpromotion\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"additionalcontactinfo\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"demographics\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary persontype (STRING);\n",
      "  optional boolean namestyle;\n",
      "  optional binary title (STRING);\n",
      "  optional binary firstname (STRING);\n",
      "  optional binary middlename (STRING);\n",
      "  optional binary lastname (STRING);\n",
      "  optional binary suffix (STRING);\n",
      "  optional int32 emailpromotion;\n",
      "  optional binary additionalcontactinfo (STRING);\n",
      "  optional binary demographics (STRING);\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:37:43 INFO JDBCRDD: closed connection                   (0 + 1) / 1]\n",
      "24/08/19 23:37:43 INFO FileOutputCommitter: Saved output of task 'attempt_202408192337422986827029190742302_0092_m_000000_72' to file:/home/wallace/spark_case_adventure/bronze/bussiness.parquet/_temporary/0/task_202408192337422986827029190742302_0092_m_000000\n",
      "24/08/19 23:37:43 INFO SparkHadoopMapRedUtil: attempt_202408192337422986827029190742302_0092_m_000000_72: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:37:43 INFO Executor: Finished task 0.0 in stage 92.0 (TID 72). 2570 bytes result sent to driver\n",
      "24/08/19 23:37:43 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 72) in 740 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:37:43 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:37:43 INFO DAGScheduler: ResultStage 92 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.788 s\n",
      "24/08/19 23:37:43 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "24/08/19 23:37:43 INFO DAGScheduler: Job 72 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.793024 s\n",
      "24/08/19 23:37:43 INFO FileFormatWriter: Start to commit write Job 181cb8de-59b8-430f-8e81-0b2e75615721.\n",
      "24/08/19 23:37:43 INFO FileFormatWriter: Write Job 181cb8de-59b8-430f-8e81-0b2e75615721 committed. Elapsed time: 30 ms.\n",
      "24/08/19 23:37:43 INFO FileFormatWriter: Finished processing stats for write job 181cb8de-59b8-430f-8e81-0b2e75615721.\n"
     ]
    }
   ],
   "source": [
    "#escrever arquivo em parquet\n",
    "df_pessoa.write.mode(\"overwrite\").parquet(\"bronze/bussiness.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "856c2b06-50ae-4c8d-a835-2708cfa124c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:37:57 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Got job 73 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Final stage: ResultStage 93 (showString at <unknown>:0)\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[206] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:37:57 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 17.5 KiB, free 434.1 MiB)\n",
      "24/08/19 23:37:57 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)\n",
      "24/08/19 23:37:57 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:37:57 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[206] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:37:57 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:37:57 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 73) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:37:57 INFO Executor: Running task 0.0 in stage 93.0 (TID 73)\n",
      "24/08/19 23:37:57 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 10.255.255.254:36873 in memory (size: 78.8 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:37:57 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:37:57 INFO Executor: Finished task 0.0 in stage 93.0 (TID 73). 3936 bytes result sent to driver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "|businessentityid|persontype|namestyle|title|firstname|middlename|  lastname|suffix|emailpromotion|additionalcontactinfo|        demographics|             rowguid|       modifieddate|\n",
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "|               1|        EM|    false| NULL|      Ken|         J|   Sánchez|  NULL|             0|                 NULL|<IndividualSurvey...|92c4279f-1207-48a...|2009-01-07 00:00:00|\n",
      "|               2|        EM|    false| NULL|    Terri|       Lee|     Duffy|  NULL|             1|                 NULL|<IndividualSurvey...|d8763459-8aa8-47c...|2008-01-24 00:00:00|\n",
      "|               3|        EM|    false| NULL|  Roberto|      NULL|Tamburello|  NULL|             0|                 NULL|<IndividualSurvey...|e1a2555e-0828-434...|2007-11-04 00:00:00|\n",
      "|               4|        EM|    false| NULL|      Rob|      NULL|   Walters|  NULL|             0|                 NULL|<IndividualSurvey...|f2d7ce06-38b3-435...|2007-11-28 00:00:00|\n",
      "|               5|        EM|    false|  Ms.|     Gail|         A|  Erickson|  NULL|             0|                 NULL|<IndividualSurvey...|f3a3f6b4-ae3b-430...|2007-12-30 00:00:00|\n",
      "|               6|        EM|    false|  Mr.|   Jossef|         H|  Goldberg|  NULL|             0|                 NULL|<IndividualSurvey...|0dea28fd-effe-482...|2013-12-16 00:00:00|\n",
      "|               7|        EM|    false| NULL|    Dylan|         A|    Miller|  NULL|             2|                 NULL|<IndividualSurvey...|c45e8ab8-01be-4b7...|2009-02-01 00:00:00|\n",
      "|               8|        EM|    false| NULL|    Diane|         L|  Margheim|  NULL|             0|                 NULL|<IndividualSurvey...|a948e590-4a56-45a...|2008-12-22 00:00:00|\n",
      "|               9|        EM|    false| NULL|     Gigi|         N|   Matthew|  NULL|             0|                 NULL|<IndividualSurvey...|5fc28c0e-6d36-425...|2009-01-09 00:00:00|\n",
      "|              10|        EM|    false| NULL|  Michael|      NULL|    Raheem|  NULL|             2|                 NULL|<IndividualSurvey...|ca2c740e-75b2-420...|2009-04-26 00:00:00|\n",
      "|              11|        EM|    false| NULL|   Ovidiu|         V|   Cracium|  NULL|             0|                 NULL|<IndividualSurvey...|d2cc2577-ef6b-440...|2010-11-28 00:00:00|\n",
      "|              12|        EM|    false| NULL|  Thierry|         B|    D'Hers|  NULL|             2|                 NULL|<IndividualSurvey...|fa263c7f-600d-4e8...|2007-12-04 00:00:00|\n",
      "|              13|        EM|    false|  Ms.|   Janice|         M|    Galvin|  NULL|             2|                 NULL|<IndividualSurvey...|34eb99e0-7042-4dc...|2010-12-16 00:00:00|\n",
      "|              14|        EM|    false| NULL|  Michael|         I|  Sullivan|  NULL|             2|                 NULL|<IndividualSurvey...|9a7501de-5caf-470...|2010-12-23 00:00:00|\n",
      "|              15|        EM|    false| NULL|   Sharon|         B| Salavaria|  NULL|             2|                 NULL|<IndividualSurvey...|beba63cb-13f1-4b7...|2011-01-11 00:00:00|\n",
      "|              16|        EM|    false| NULL|    David|         M|   Bradley|  NULL|             1|                 NULL|<IndividualSurvey...|2cc8ba72-5dbb-497...|2007-12-13 00:00:00|\n",
      "|              17|        EM|    false| NULL|    Kevin|         F|     Brown|  NULL|             2|                 NULL|<IndividualSurvey...|9ee4713e-b3d8-440...|2007-01-19 00:00:00|\n",
      "|              18|        EM|    false| NULL|     John|         L|      Wood|  NULL|             2|                 NULL|<IndividualSurvey...|fe21bda7-9327-4d1...|2011-01-31 00:00:00|\n",
      "|              19|        EM|    false| NULL|     Mary|         A|   Dempsey|  NULL|             1|                 NULL|<IndividualSurvey...|36f04305-6769-4e6...|2011-02-07 00:00:00|\n",
      "|              20|        EM|    false| NULL|   Wanida|         M|  Benshoof|  NULL|             2|                 NULL|<IndividualSurvey...|1e7e56f4-a583-4e3...|2010-12-31 00:00:00|\n",
      "+----------------+----------+---------+-----+---------+----------+----------+------+--------------+---------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:37:57 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 73) in 241 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:37:57 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:37:57 INFO DAGScheduler: ResultStage 93 (showString at <unknown>:0) finished in 0.257 s\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:37:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "24/08/19 23:37:57 INFO DAGScheduler: Job 73 finished: showString at <unknown>:0, took 0.297616 s\n"
     ]
    }
   ],
   "source": [
    "df_pessoa.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7fe81b14-803e-49e3-8b59-66da72337127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fornecedor = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"Purchasing.vendor\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a2c7aa5c-22a7-4d83-a88b-045198252427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:04:53 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:04:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:04:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:04:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:04:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:04:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:04:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:04:54 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Got job 42 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Final stage: ResultStage 50 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[122] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:04:54 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 216.3 KiB, free 434.2 MiB)\n",
      "24/08/19 23:04:54 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 78.1 KiB, free 434.1 MiB)\n",
      "24/08/19 23:04:54 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.255.255.254:36873 (size: 78.1 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:04:54 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:04:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[122] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:04:54 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:04:54 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 42) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:04:54 INFO Executor: Running task 0.0 in stage 50.0 (TID 42)\n",
      "24/08/19 23:04:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:04:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:04:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:04:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:04:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:04:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:04:55 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:04:55 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:04:55 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:04:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"accountnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"creditrating\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"preferredvendorstatus\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"activeflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"purchasingwebserviceurl\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(1024)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary accountnumber (STRING);\n",
      "  optional binary name (STRING);\n",
      "  optional int32 creditrating (INTEGER(16,true));\n",
      "  optional boolean preferredvendorstatus;\n",
      "  optional boolean activeflag;\n",
      "  optional binary purchasingwebserviceurl (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:04:55 INFO JDBCRDD: closed connection                   (0 + 1) / 1]\n",
      "24/08/19 23:04:55 INFO FileOutputCommitter: Saved output of task 'attempt_202408192304545399104786229420787_0050_m_000000_42' to file:/home/wallace/spark_case_adventure/bronze/fornecedor.parquet/_temporary/0/task_202408192304545399104786229420787_0050_m_000000\n",
      "24/08/19 23:04:55 INFO SparkHadoopMapRedUtil: attempt_202408192304545399104786229420787_0050_m_000000_42: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:04:55 INFO Executor: Finished task 0.0 in stage 50.0 (TID 42). 2570 bytes result sent to driver\n",
      "24/08/19 23:04:55 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 42) in 969 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:04:55 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:04:55 INFO DAGScheduler: ResultStage 50 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.219 s\n",
      "24/08/19 23:04:55 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:04:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished\n",
      "24/08/19 23:04:55 INFO DAGScheduler: Job 42 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.246222 s\n",
      "24/08/19 23:04:55 INFO FileFormatWriter: Start to commit write Job 6afec62a-1944-4042-8546-e9b970f913d8.\n",
      "24/08/19 23:04:56 INFO FileFormatWriter: Write Job 6afec62a-1944-4042-8546-e9b970f913d8 committed. Elapsed time: 69 ms.\n",
      "24/08/19 23:04:56 INFO FileFormatWriter: Finished processing stats for write job 6afec62a-1944-4042-8546-e9b970f913d8.\n"
     ]
    }
   ],
   "source": [
    "#escrever arquivo em parquet\n",
    "df_fornecedor.write.mode(\"overwrite\").parquet(\"bronze/fornecedor.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "caf6ac23-f0c8-4b33-99a6-d34b0e8b9f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+------------+---------------------+----------+-----------------------+-------------------+\n",
      "|businessentityid|accountnumber|                name|creditrating|preferredvendorstatus|activeflag|purchasingwebserviceurl|       modifieddate|\n",
      "+----------------+-------------+--------------------+------------+---------------------+----------+-----------------------+-------------------+\n",
      "|            1492| AUSTRALI0001|Australia Bike Re...|           1|                 true|      true|                   NULL|2011-12-23 00:00:00|\n",
      "|            1494| ALLENSON0001|     Allenson Cycles|           2|                 true|      true|                   NULL|2011-04-25 00:00:00|\n",
      "|            1496| ADVANCED0001|   Advanced Bicycles|           1|                 true|      true|                   NULL|2011-04-25 00:00:00|\n",
      "|            1498|   TRIKES0001|        Trikes, Inc.|           2|                 true|      true|                   NULL|2012-02-03 00:00:00|\n",
      "|            1500|  MORGANB0001|Morgan Bike Acces...|           1|                 true|      true|                   NULL|2012-02-02 00:00:00|\n",
      "|            1502|  CYCLING0001|      Cycling Master|           1|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "|            1504|  CHICAGO0002|    Chicago Rent-All|           2|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "|            1506| GREENWOO0001|Greenwood Athleti...|           1|                 true|      true|                   NULL|2012-01-25 00:00:00|\n",
      "|            1508|  COMPETE0001|Compete Enterpris...|           1|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "|            1510| INTERNAT0001|       International|           1|                 true|      true|                   NULL|2012-01-25 00:00:00|\n",
      "|            1512|  LIGHTSP0001|         Light Speed|           1|                 true|      true|                   NULL|2011-12-23 00:00:00|\n",
      "|            1514| TRAINING0001|    Training Systems|           1|                 true|      true|                   NULL|2012-02-03 00:00:00|\n",
      "|            1516|  GARDNER0001|Gardner Touring C...|           1|                false|     false|                   NULL|2012-01-25 00:00:00|\n",
      "|            1518| INTERNAT0004|International Tre...|           1|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "|            1520|    G&KBI0001| G & K Bicycle Corp.|           1|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "|            1522|  FIRSTNA0001|First National Sp...|           1|                 true|      true|                   NULL|2012-01-25 00:00:00|\n",
      "|            1524| RECREATI0001|    Recreation Place|           4|                 true|      true|                   NULL|2012-02-02 00:00:00|\n",
      "|            1526| INTERNAT0002|International Bic...|           1|                 true|      true|                   NULL|2012-01-25 00:00:00|\n",
      "|            1528|  IMAGEMA0001|Image Makers Bike...|           1|                 true|      true|                   NULL|2012-02-03 00:00:00|\n",
      "|            1530|  COMFORT0001|Comfort Road Bicy...|           1|                 true|      true|                   NULL|2011-12-24 00:00:00|\n",
      "+----------------+-------------+--------------------+------------+---------------------+----------+-----------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:05:13 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Got job 43 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Final stage: ResultStage 51 (showString at <unknown>:0)\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[125] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:05:13 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 15.0 KiB, free 434.1 MiB)\n",
      "24/08/19 23:05:13 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.1 MiB)\n",
      "24/08/19 23:05:13 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.255.255.254:36873 (size: 7.2 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:05:13 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 10.255.255.254:36873 in memory (size: 78.1 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:05:13 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[125] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:05:13 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:05:13 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 43) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:05:13 INFO Executor: Running task 0.0 in stage 51.0 (TID 43)\n",
      "24/08/19 23:05:13 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:05:13 INFO Executor: Finished task 0.0 in stage 51.0 (TID 43). 2776 bytes result sent to driver\n",
      "24/08/19 23:05:13 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 43) in 65 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:05:13 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:05:13 INFO DAGScheduler: ResultStage 51 (showString at <unknown>:0) finished in 0.103 s\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:05:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "24/08/19 23:05:13 INFO DAGScheduler: Job 43 finished: showString at <unknown>:0, took 0.152386 s\n"
     ]
    }
   ],
   "source": [
    "df_fornecedor.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827cec4f-308f-4639-9560-920e847ed6f4",
   "metadata": {},
   "source": [
    "#Tabela Bussiness sendo consultada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ce1b8bf5-cb0b-4a7c-b09a-cb98c439e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bussiness = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"person.businessentity\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f8b081a8-61dc-4061-bea5-a973c4308e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:06:20 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:06:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:06:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:06:20 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Got job 44 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Final stage: ResultStage 52 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[128] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:06:20 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 213.5 KiB, free 434.2 MiB)\n",
      "24/08/19 23:06:20 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 434.1 MiB)\n",
      "24/08/19 23:06:20 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 10.255.255.254:36873 in memory (size: 7.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:06:20 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.255.255.254:36873 (size: 77.4 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:06:20 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[128] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:06:20 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:06:20 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 44) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:06:20 INFO Executor: Running task 0.0 in stage 52.0 (TID 44)\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:06:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:06:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:06:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:06:20 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:06:20 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:06:20 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:06:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:06:21 INFO JDBCRDD: closed connection                   (0 + 1) / 1]\n",
      "24/08/19 23:06:21 INFO FileOutputCommitter: Saved output of task 'attempt_202408192306203331375764757975058_0052_m_000000_44' to file:/home/wallace/spark_case_adventure/bronze/bussiness.parquet/_temporary/0/task_202408192306203331375764757975058_0052_m_000000\n",
      "24/08/19 23:06:21 INFO SparkHadoopMapRedUtil: attempt_202408192306203331375764757975058_0052_m_000000_44: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:06:21 INFO Executor: Finished task 0.0 in stage 52.0 (TID 44). 2570 bytes result sent to driver\n",
      "24/08/19 23:06:21 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 44) in 890 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:06:21 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:06:21 INFO DAGScheduler: ResultStage 52 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.914 s\n",
      "24/08/19 23:06:21 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:06:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "24/08/19 23:06:21 INFO DAGScheduler: Job 44 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.921985 s\n",
      "24/08/19 23:06:21 INFO FileFormatWriter: Start to commit write Job 5d19f6c7-82fe-411d-b357-8c8bc49a6050.\n",
      "24/08/19 23:06:21 INFO FileFormatWriter: Write Job 5d19f6c7-82fe-411d-b357-8c8bc49a6050 committed. Elapsed time: 67 ms.\n",
      "24/08/19 23:06:21 INFO FileFormatWriter: Finished processing stats for write job 5d19f6c7-82fe-411d-b357-8c8bc49a6050.\n"
     ]
    }
   ],
   "source": [
    "#escrever arquivo em parquet camada bronze\n",
    "df_bussiness.write.mode(\"overwrite\").parquet(\"bronze/bussiness.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2253396-0eef-43cd-b036-70cea10f4bd0",
   "metadata": {},
   "source": [
    "#Lendo consulta de bussiness e endereço "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eb5ca9f5-802e-44bb-84bd-2f2d4ae36f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bussiness_endereco = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"person.businessentityaddress\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "def2382f-ba1d-4bfe-801a-cf154e23ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- businessentityid: integer (nullable = true)\n",
      " |-- addressid: integer (nullable = true)\n",
      " |-- addresstypeid: integer (nullable = true)\n",
      " |-- rowguid: string (nullable = true)\n",
      " |-- modifieddate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bussiness_endereco.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c00c09fc-6fdc-42df-b964-17ebef78e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:07:39 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:40 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Got job 45 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[131] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:07:40 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 214.4 KiB, free 433.9 MiB)\n",
      "24/08/19 23:07:40 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 433.8 MiB)\n",
      "24/08/19 23:07:40 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.255.255.254:36873 (size: 77.7 KiB, free: 434.2 MiB)\n",
      "24/08/19 23:07:40 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[131] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:07:40 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:07:40 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 45) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:07:40 INFO Executor: Running task 0.0 in stage 53.0 (TID 45)\n",
      "24/08/19 23:07:40 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 10.255.255.254:36873 in memory (size: 77.4 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:07:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:40 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:07:40 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:07:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:07:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"addressid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"addresstypeid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional int32 addressid;\n",
      "  optional int32 addresstypeid;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:07:40 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:07:40 INFO FileOutputCommitter: Saved output of task 'attempt_202408192307408447489645357480433_0053_m_000000_45' to file:/home/wallace/spark_case_adventure/bronze/bussiness_endereco.parquet/_temporary/0/task_202408192307408447489645357480433_0053_m_000000\n",
      "24/08/19 23:07:40 INFO SparkHadoopMapRedUtil: attempt_202408192307408447489645357480433_0053_m_000000_45: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:07:40 INFO Executor: Finished task 0.0 in stage 53.0 (TID 45). 2484 bytes result sent to driver\n",
      "24/08/19 23:07:40 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 45) in 344 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:07:40 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:07:40 INFO DAGScheduler: ResultStage 53 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.387 s\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:07:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "24/08/19 23:07:40 INFO DAGScheduler: Job 45 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.394079 s\n",
      "24/08/19 23:07:40 INFO FileFormatWriter: Start to commit write Job 4856ac63-549b-4652-a704-72b8a84c7a5e.\n",
      "24/08/19 23:07:40 INFO FileFormatWriter: Write Job 4856ac63-549b-4652-a704-72b8a84c7a5e committed. Elapsed time: 9 ms.\n",
      "24/08/19 23:07:40 INFO FileFormatWriter: Finished processing stats for write job 4856ac63-549b-4652-a704-72b8a84c7a5e.\n"
     ]
    }
   ],
   "source": [
    "#escrever arquivo em parquet\n",
    "df_bussiness_endereco.write.mode(\"overwrite\").parquet(\"bronze/bussiness_endereco.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612513b-0bcb-46c2-96d7-5a7c8bf0aea1",
   "metadata": {},
   "source": [
    "#Lendo consulta de endereços \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1570b70c-cea3-41dd-8d74-c39019cbdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_endereco = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"person.address\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "25bc9278-8c7d-4180-9b74-b52192e85801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:07:53 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:53 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:07:53 INFO DAGScheduler: Got job 46 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:07:53 INFO DAGScheduler: Final stage: ResultStage 54 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:07:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:07:53 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:07:53 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[134] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:07:53 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 216.7 KiB, free 433.9 MiB)\n",
      "24/08/19 23:07:54 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 78.0 KiB, free 433.8 MiB)\n",
      "24/08/19 23:07:54 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.255.255.254:36873 (size: 78.0 KiB, free: 434.2 MiB)\n",
      "24/08/19 23:07:54 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:07:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[134] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:07:54 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:07:54 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 46) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/19 23:07:54 INFO Executor: Running task 0.0 in stage 54.0 (TID 46)\n",
      "24/08/19 23:07:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:07:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:07:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:07:54 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:07:54 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:07:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:07:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"addressid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"addressline1\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(60)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"addressline2\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(60)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(30)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"stateprovinceid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"postalcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"spatiallocation\",\n",
      "    \"type\" : \"binary\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 addressid;\n",
      "  optional binary addressline1 (STRING);\n",
      "  optional binary addressline2 (STRING);\n",
      "  optional binary city (STRING);\n",
      "  optional int32 stateprovinceid;\n",
      "  optional binary postalcode (STRING);\n",
      "  optional binary spatiallocation;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:07:54 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 10.255.255.254:36873 in memory (size: 77.7 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:07:54 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:07:54 INFO FileOutputCommitter: Saved output of task 'attempt_202408192307535079348854382951925_0054_m_000000_46' to file:/home/wallace/spark_case_adventure/bronze/endereco.parquet/_temporary/0/task_202408192307535079348854382951925_0054_m_000000\n",
      "24/08/19 23:07:54 INFO SparkHadoopMapRedUtil: attempt_202408192307535079348854382951925_0054_m_000000_46: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:07:54 INFO Executor: Finished task 0.0 in stage 54.0 (TID 46). 2570 bytes result sent to driver\n",
      "24/08/19 23:07:54 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 46) in 595 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:07:54 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:07:54 INFO DAGScheduler: ResultStage 54 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.124 s\n",
      "24/08/19 23:07:54 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:07:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "24/08/19 23:07:54 INFO DAGScheduler: Job 46 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.130207 s\n",
      "24/08/19 23:07:54 INFO FileFormatWriter: Start to commit write Job c9a36148-7735-4f86-a972-60ec8328fc13.\n",
      "24/08/19 23:07:54 INFO FileFormatWriter: Write Job c9a36148-7735-4f86-a972-60ec8328fc13 committed. Elapsed time: 33 ms.\n",
      "24/08/19 23:07:54 INFO FileFormatWriter: Finished processing stats for write job c9a36148-7735-4f86-a972-60ec8328fc13.\n"
     ]
    }
   ],
   "source": [
    "#escrever arquivo em parquet na camada bronze\n",
    "df_endereco.write.mode(\"overwrite\").parquet(\"bronze/endereco.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "443a0c2d-4489-470a-8ed8-5e1c793e5a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 22:38:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.255.255.254:36873 in memory (size: 9.2 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO CodeGenerator: Code generated in 7.7832 ms\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Registering RDD 104 (showString at <unknown>:0) as input to shuffle 4\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Got map stage job 34 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (showString at <unknown>:0)\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[104] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 15.3 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[104] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:11 INFO CodeGenerator: Code generated in 7.2657 ms\n",
      "24/08/19 22:38:11 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:11 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 34) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 22:38:11 INFO Executor: Running task 0.0 in stage 38.0 (TID 34)\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Registering RDD 106 (showString at <unknown>:0) as input to shuffle 5\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Got map stage job 35 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (showString at <unknown>:0)\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[106] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 13.9 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[106] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:11 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:11 INFO CodeGenerator: Code generated in 14.4605 ms\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Registering RDD 108 (showString at <unknown>:0) as input to shuffle 6\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Got map stage job 36 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (showString at <unknown>:0)\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[108] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 14.6 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[108] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:11 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:11 INFO CodeGenerator: Code generated in 23.8358 ms\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Registering RDD 110 (showString at <unknown>:0) as input to shuffle 7\n",
      "24/08/19 22:38:11 INFO CodeGenerator: Code generated in 8.2645 ms\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Got map stage job 37 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (showString at <unknown>:0)\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[110] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 14.4 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 423.5 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[110] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:11 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.255.255.254:36873 in memory (size: 5.6 KiB, free: 430.9 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.255.255.254:36873 in memory (size: 1137.8 KiB, free: 432.0 MiB)\n",
      "24/08/19 22:38:11 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.255.255.254:36873 in memory (size: 2.3 MiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:12 INFO JDBCRDD: closed connection 1][Stage 40:>   (0 + 0) / 1]1]\n",
      "24/08/19 22:38:12 INFO Executor: Finished task 0.0 in stage 38.0 (TID 34). 2034 bytes result sent to driver\n",
      "24/08/19 22:38:12 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 35) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 22:38:12 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 34) in 904 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:12 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:12 INFO Executor: Running task 0.0 in stage 39.0 (TID 35)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: ShuffleMapStage 38 (showString at <unknown>:0) finished in 0.913 s\n",
      "24/08/19 22:38:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 22:38:12 INFO DAGScheduler: running: Set(ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 22:38:12 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 22:38:12 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 22:38:12 INFO CodeGenerator: Code generated in 4.7678 ms\n",
      "24/08/19 22:38:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Got job 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Final stage: ResultStage 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[112] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 22:38:12 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)\n",
      "24/08/19 22:38:12 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.3 MiB)\n",
      "24/08/19 22:38:12 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:12 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[112] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:12 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:12 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:12 INFO JDBCRDD: closed connection\n",
      "24/08/19 22:38:12 INFO Executor: Finished task 0.0 in stage 39.0 (TID 35). 2034 bytes result sent to driver\n",
      "24/08/19 22:38:12 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 36) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 22:38:12 INFO Executor: Running task 0.0 in stage 40.0 (TID 36)\n",
      "24/08/19 22:38:12 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 35) in 289 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:12 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:12 INFO DAGScheduler: ShuffleMapStage 39 (showString at <unknown>:0) finished in 1.184 s\n",
      "24/08/19 22:38:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 22:38:12 INFO DAGScheduler: running: Set(ResultStage 43, ShuffleMapStage 40, ShuffleMapStage 41)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 22:38:12 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 22:38:12 INFO CodeGenerator: Code generated in 35.9438 ms  (0 + 0) / 1]\n",
      "24/08/19 22:38:12 INFO JDBCRDD: closed connection\n",
      "24/08/19 22:38:12 INFO Executor: Finished task 0.0 in stage 40.0 (TID 36). 1948 bytes result sent to driver\n",
      "24/08/19 22:38:12 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 37) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 22:38:12 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 36) in 203 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:12 INFO Executor: Running task 0.0 in stage 41.0 (TID 37)\n",
      "24/08/19 22:38:12 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:12 INFO DAGScheduler: ShuffleMapStage 40 (showString at <unknown>:0) finished in 1.283 s\n",
      "24/08/19 22:38:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 22:38:12 INFO DAGScheduler: running: Set(ResultStage 43, ShuffleMapStage 41)\n",
      "24/08/19 22:38:12 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 22:38:12 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 22:38:12 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 22:38:12 INFO CodeGenerator: Code generated in 61.089501 ms\n",
      "24/08/19 22:38:13 INFO JDBCRDD: closed connection\n",
      "24/08/19 22:38:13 INFO Executor: Finished task 0.0 in stage 41.0 (TID 37). 1948 bytes result sent to driver\n",
      "24/08/19 22:38:13 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 38) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 22:38:13 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 37) in 617 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:13 INFO Executor: Running task 0.0 in stage 43.0 (TID 38)\n",
      "24/08/19 22:38:13 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:13 INFO DAGScheduler: ShuffleMapStage 41 (showString at <unknown>:0) finished in 1.791 s\n",
      "24/08/19 22:38:13 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 22:38:13 INFO DAGScheduler: running: Set(ResultStage 43)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 22:38:13 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 22:38:13 INFO ShuffleBlockFetcherIterator: Getting 1 (10.8 KiB) non-empty blocks including 1 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 22:38:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 53 ms\n",
      "24/08/19 22:38:13 INFO Executor: Finished task 0.0 in stage 43.0 (TID 38). 7721 bytes result sent to driver\n",
      "24/08/19 22:38:13 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 22:38:13 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 38) in 162 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:13 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:13 INFO DAGScheduler: ResultStage 43 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.189 s\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 22:38:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Job 38 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.223357 s\n",
      "24/08/19 22:38:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Got job 39 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Final stage: ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 1025.6 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[114] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.255.255.254:36873 (size: 4.7 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 8.2 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO SparkContext: Created broadcast 42 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:13 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[114] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:13 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:13 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 39) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 22:38:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:13 INFO Executor: Running task 0.0 in stage 45.0 (TID 39)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Got job 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Final stage: ResultStage 47 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 22:38:13 INFO ShuffleBlockFetcherIterator: Getting 1 (262.2 KiB) non-empty blocks including 1 (262.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 8.2 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 22:38:13 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "24/08/19 22:38:13 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:38:13 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[116] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:13 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:13 INFO Executor: Finished task 0.0 in stage 45.0 (TID 39). 202260 bytes result sent to driver\n",
      "24/08/19 22:38:14 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 40) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 22:38:14 INFO Executor: Running task 0.0 in stage 47.0 (TID 40)\n",
      "24/08/19 22:38:14 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 39) in 277 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:14 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:14 INFO DAGScheduler: ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.284 s\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 22:38:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Job 39 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.300775 s\n",
      "24/08/19 22:38:14 INFO ShuffleBlockFetcherIterator: Getting 1 (395.4 KiB) non-empty blocks including 1 (395.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 22:38:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 22:38:14 INFO Executor: Finished task 0.0 in stage 47.0 (TID 40). 288665 bytes result sent to driver\n",
      "24/08/19 22:38:14 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 40) in 27 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:14 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:14 INFO DAGScheduler: ResultStage 47 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.285 s\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 22:38:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Job 40 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.303889 s\n",
      "24/08/19 22:38:14 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 1186.3 KiB, free 432.1 MiB)\n",
      "24/08/19 22:38:14 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 1278.1 KiB, free 430.9 MiB)\n",
      "24/08/19 22:38:14 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 269.5 KiB, free 430.6 MiB)\n",
      "24/08/19 22:38:14 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.255.255.254:36873 (size: 269.5 KiB, free: 434.1 MiB)\n",
      "24/08/19 22:38:14 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:14 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 350.8 KiB, free 430.3 MiB)\n",
      "24/08/19 22:38:14 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.255.255.254:36873 (size: 350.8 KiB, free: 433.8 MiB)\n",
      "24/08/19 22:38:14 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 22:38:14 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 22:38:14 INFO CodeGenerator: Code generated in 13.1824 ms\n",
      "24/08/19 22:38:14 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Got job 41 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Final stage: ResultStage 49 (showString at <unknown>:0)\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 22:38:14 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[119] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 22:38:15 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 17.0 KiB, free 430.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "|businessentityid|accountnumber|                name|creditrating|          city|\n",
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "|            1580|  LITWARE0001|       Litware, Inc.|           1|    Santa Cruz|\n",
      "|            1522|  FIRSTNA0001|First National Sp...|           1|         Boise|\n",
      "|            1618|  METROSP0001|Metro Sport Equip...|           1|       Lebanon|\n",
      "|            1650| AMERICAN0001|American Bicycles...|           1|   West Covina|\n",
      "|            1500|  MORGANB0001|Morgan Bike Acces...|           1|        Albany|\n",
      "|            1496| ADVANCED0001|   Advanced Bicycles|           1|      Lynnwood|\n",
      "|            1510| INTERNAT0001|       International|           1|Salt Lake City|\n",
      "|            1574|  JEFFSSP0001|Jeff's Sporting G...|           1|      Glendale|\n",
      "|            1634|   GMASKI0001|      GMA Ski & Bike|           1|     Bremerton|\n",
      "|            1564| ILLINOIS0001|Illinois Trek & C...|           1|   Mill Valley|\n",
      "|            1582|  INNERCI0001|    Inner City Bikes|           3|       W. Linn|\n",
      "|            1550|  MERITBI0001|         Merit Bikes|           5|     Bremerton|\n",
      "|            1506| GREENWOO0001|Greenwood Athleti...|           1|   Lemon Grove|\n",
      "|            1588| SIGNATUR0001|    Signature Cycles|           2|      Coronado|\n",
      "|            1512|  LIGHTSP0001|         Light Speed|           1| Spring Valley|\n",
      "|            1542|  HILLSBI0001|Hill's Bicycle Se...|           1|      Richmond|\n",
      "|            1586| MITCHELL0001|     Mitchell Sports|           1|       Everett|\n",
      "|            1694|  COMPETE0002|       Compete, Inc.|           1|        Dallas|\n",
      "|            1590| SUPERSAL0001|     SUPERSALES INC.|           1|      Lakewood|\n",
      "|            1626|  HILLBIC0001| Hill Bicycle Center|           1|       Oakland|\n",
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 22:38:15 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 430.3 MiB)\n",
      "24/08/19 22:38:15 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.7 MiB)\n",
      "24/08/19 22:38:15 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 22:38:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[119] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 22:38:15 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "24/08/19 22:38:15 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 41) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 22:38:15 INFO Executor: Running task 0.0 in stage 49.0 (TID 41)\n",
      "24/08/19 22:38:15 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 22:38:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 22:38:15 INFO CodeGenerator: Code generated in 89.469802 ms\n",
      "24/08/19 22:38:15 INFO Executor: Finished task 0.0 in stage 49.0 (TID 41). 4714 bytes result sent to driver\n",
      "24/08/19 22:38:15 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 41) in 106 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 22:38:15 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "24/08/19 22:38:15 INFO DAGScheduler: ResultStage 49 (showString at <unknown>:0) finished in 0.212 s\n",
      "24/08/19 22:38:15 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 22:38:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "24/08/19 22:38:15 INFO DAGScheduler: Job 41 finished: showString at <unknown>:0, took 0.219339 s\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 10.255.255.254:36873 in memory (size: 269.5 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 10.255.255.254:36873 in memory (size: 4.7 KiB, free: 434.0 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 10.255.255.254:36873 in memory (size: 350.8 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:57:30 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:57:31 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 22:57:31 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "#a. Localização e informações de fornecedores, fábricas, lojas e centros de distribuição;\n",
    "df_fornecedor_local = df_fornecedor.join(df_bussiness,'businessentityid','inner')\\\n",
    "             .join(df_bussiness_endereco,'businessentityid')\\\n",
    "             .join(df_endereco,'addressid').select(df_bussiness.businessentityid,df_fornecedor.accountnumber,df_fornecedor.name,df_fornecedor.creditrating,df_endereco.city)\n",
    "df_fornecedor_local.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "53a5b989-9e3d-4fc9-adc7-76ce572c190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:11:13 INFO DAGScheduler: Registering RDD 140 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 8\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Got map stage job 47 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[140] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 15.3 KiB, free 434.1 MiB)\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.1 MiB)\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[140] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Registering RDD 142 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 9\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Got map stage job 48 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Final stage: ShuffleMapStage 56 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[142] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 47) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:13 INFO Executor: Running task 0.0 in stage 55.0 (TID 47)\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 13.9 KiB, free 434.1 MiB)\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 434.1 MiB)\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[142] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Registering RDD 144 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 10\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Got map stage job 49 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[144] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 14.6 KiB, free 434.1 MiB)\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[144] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Registering RDD 146 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 11\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Got map stage job 50 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Final stage: ShuffleMapStage 58 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[146] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 14.4 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:13 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:13 INFO Executor: Finished task 0.0 in stage 55.0 (TID 47). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 48) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:13 INFO Executor: Running task 0.0 in stage 56.0 (TID 48)\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 47) in 61 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[146] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:13 INFO DAGScheduler: ShuffleMapStage 55 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.090 s\n",
      "24/08/19 23:11:13 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:13 INFO DAGScheduler: running: Set(ShuffleMapStage 56, ShuffleMapStage 57, ShuffleMapStage 58)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:13 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Got job 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[148] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 8.2 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:13 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[148] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:13 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:13 INFO Executor: Finished task 0.0 in stage 56.0 (TID 48). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 49) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:13 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 48) in 100 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:13 INFO Executor: Running task 0.0 in stage 57.0 (TID 49)\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:13 INFO DAGScheduler: ShuffleMapStage 56 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.148 s\n",
      "24/08/19 23:11:13 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:13 INFO DAGScheduler: running: Set(ResultStage 60, ShuffleMapStage 57, ShuffleMapStage 58)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:13 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:13 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:13 INFO Executor: Finished task 0.0 in stage 57.0 (TID 49). 2034 bytes result sent to driver\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 50) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:13 INFO Executor: Running task 0.0 in stage 58.0 (TID 50)\n",
      "24/08/19 23:11:13 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 49) in 78 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:13 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:13 INFO DAGScheduler: ShuffleMapStage 57 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.210 s\n",
      "24/08/19 23:11:13 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:13 INFO DAGScheduler: running: Set(ResultStage 60, ShuffleMapStage 58)\n",
      "24/08/19 23:11:13 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:13 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:13 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Got job 52 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Final stage: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 8.2 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.0 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.3 MiB)\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 10.255.255.254:36873 in memory (size: 78.0 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:14 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:14 INFO Executor: Finished task 0.0 in stage 58.0 (TID 50). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 51) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:14 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 50) in 217 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:14 INFO Executor: Running task 0.0 in stage 60.0 (TID 51)\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:14 INFO DAGScheduler: ShuffleMapStage 58 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.407 s\n",
      "24/08/19 23:11:14 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:14 INFO DAGScheduler: running: Set(ResultStage 60, ResultStage 62)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:14 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Getting 1 (10.8 KiB) non-empty blocks including 1 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:14 INFO Executor: Finished task 0.0 in stage 60.0 (TID 51). 7721 bytes result sent to driver\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 52) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:14 INFO Executor: Running task 0.0 in stage 62.0 (TID 52)\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 51) in 35 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:14 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:14 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.341 s\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 51 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.344547 s\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Getting 1 (262.2 KiB) non-empty blocks including 1 (262.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 1025.6 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.255.255.254:36873 (size: 4.7 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 59 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Got job 53 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Final stage: ResultStage 64 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 8.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:14 INFO Executor: Finished task 0.0 in stage 62.0 (TID 52). 202303 bytes result sent to driver\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 52) in 49 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[152] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:14 INFO DAGScheduler: ResultStage 62 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.168 s\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 53) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished\n",
      "24/08/19 23:11:14 INFO Executor: Running task 0.0 in stage 64.0 (TID 53)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 52 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.173116 s\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Getting 1 (395.4 KiB) non-empty blocks including 1 (395.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/08/19 23:11:14 INFO Executor: Finished task 0.0 in stage 64.0 (TID 53). 288665 bytes result sent to driver\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 53) in 13 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:14 INFO DAGScheduler: ResultStage 64 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.026 s\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 53 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.041858 s\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 1186.3 KiB, free 432.2 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 1278.1 KiB, free 430.9 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 269.5 KiB, free 430.6 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 350.8 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.255.255.254:36873 (size: 269.5 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.255.255.254:36873 (size: 350.8 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 61 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 62 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:14 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:14 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:11:14 INFO CodeGenerator: Code generated in 50.685 ms\n",
      "24/08/19 23:11:14 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Got job 54 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Final stage: ResultStage 66 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[155] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 219.9 KiB, free 430.1 MiB)\n",
      "24/08/19 23:11:14 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 430.0 MiB)\n",
      "24/08/19 23:11:14 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.255.255.254:36873 (size: 79.0 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:14 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[155] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 54) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:14 INFO Executor: Running task 0.0 in stage 66.0 (TID 54)\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:14 INFO CodeGenerator: Code generated in 5.882 ms\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:11:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:11:14 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:11:14 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:11:14 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:11:14 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"accountnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"creditrating\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(30)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary accountnumber (STRING);\n",
      "  optional binary name (STRING);\n",
      "  optional int32 creditrating (INTEGER(16,true));\n",
      "  optional binary city (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:11:14 INFO FileOutputCommitter: Saved output of task 'attempt_202408192311147910366958715478119_0066_m_000000_54' to file:/home/wallace/spark_case_adventure/silver/localizacao_fabricas.parquet/_temporary/0/task_202408192311147910366958715478119_0066_m_000000\n",
      "24/08/19 23:11:14 INFO SparkHadoopMapRedUtil: attempt_202408192311147910366958715478119_0066_m_000000_54: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:11:14 INFO Executor: Finished task 0.0 in stage 66.0 (TID 54). 5087 bytes result sent to driver\n",
      "24/08/19 23:11:14 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 54) in 105 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:14 INFO DAGScheduler: ResultStage 66 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.166 s\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished\n",
      "24/08/19 23:11:14 INFO DAGScheduler: Job 54 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.171261 s\n",
      "24/08/19 23:11:14 INFO FileFormatWriter: Start to commit write Job cda044b7-5f51-414c-9750-e156fa5b6c4d.\n",
      "24/08/19 23:11:14 INFO FileFormatWriter: Write Job cda044b7-5f51-414c-9750-e156fa5b6c4d committed. Elapsed time: 8 ms.\n",
      "24/08/19 23:11:14 INFO FileFormatWriter: Finished processing stats for write job cda044b7-5f51-414c-9750-e156fa5b6c4d.\n",
      "24/08/19 23:11:18 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:18 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:18 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 10.255.255.254:36873 in memory (size: 79.0 KiB, free: 433.8 MiB)\n"
     ]
    }
   ],
   "source": [
    "df_fornecedor_local.write.mode(\"overwrite\").parquet(\"silver/localizacao_fabricas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "49a42e92-44b1-498b-8a41-24d83b7de08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:11:30 INFO DAGScheduler: Registering RDD 161 (showString at <unknown>:0) as input to shuffle 12\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got map stage job 55 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ShuffleMapStage 67 (showString at <unknown>:0)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[161] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 15.3 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[161] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Registering RDD 163 (showString at <unknown>:0) as input to shuffle 13\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 55) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got map stage job 56 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ShuffleMapStage 68 (showString at <unknown>:0)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[163] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 67.0 (TID 55)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 13.9 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[163] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Registering RDD 165 (showString at <unknown>:0) as input to shuffle 14\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got map stage job 57 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (showString at <unknown>:0)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[165] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 14.6 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[165] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Registering RDD 167 (showString at <unknown>:0) as input to shuffle 15\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got map stage job 58 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (showString at <unknown>:0)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[167] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 14.4 KiB, free 430.2 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 430.2 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[167] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 67.0 (TID 55). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 56) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 55) in 72 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 68.0 (TID 56)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ShuffleMapStage 67 (showString at <unknown>:0) finished in 0.162 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:30 INFO DAGScheduler: running: Set(ShuffleMapStage 70, ShuffleMapStage 68, ShuffleMapStage 69)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:11:30 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 10.255.255.254:36873 in memory (size: 350.8 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got job 59 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 68.0 (TID 56). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 57) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 69.0 (TID 57)\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 56) in 76 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 8.2 KiB, free 431.8 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 431.8 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[169] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO DAGScheduler: ShuffleMapStage 68 (showString at <unknown>:0) finished in 0.150 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:30 INFO DAGScheduler: running: Set(ShuffleMapStage 70, ResultStage 72, ShuffleMapStage 69)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 10.255.255.254:36873 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 10.255.255.254:36873 in memory (size: 269.5 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 69.0 (TID 57). 2034 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 58) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 70.0 (TID 58)\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 57) in 156 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ShuffleMapStage 69 (showString at <unknown>:0) finished in 0.290 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:30 INFO DAGScheduler: running: Set(ShuffleMapStage 70, ResultStage 72)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:30 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got job 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[171] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[171] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 70.0 (TID 58). 1948 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 59) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 58) in 118 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 72.0 (TID 59)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ShuffleMapStage 70 (showString at <unknown>:0) finished in 0.386 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:11:30 INFO DAGScheduler: running: Set(ResultStage 74, ResultStage 72)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Getting 1 (10.8 KiB) non-empty blocks including 1 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 72.0 (TID 59). 7721 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 60) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 59) in 6 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 74.0 (TID 60)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ResultStage 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.268 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 59 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.298058 s\n",
      "24/08/19 23:11:30 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Getting 1 (262.2 KiB) non-empty blocks including 1 (262.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 1025.6 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.255.255.254:36873 (size: 4.7 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 70 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 74.0 (TID 60). 202260 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 60) in 23 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.084 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 60 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.087807 s\n",
      "24/08/19 23:11:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got job 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[173] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 8.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[173] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 61) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 76.0 (TID 61)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 1186.3 KiB, free 432.2 MiB)\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Getting 1 (395.4 KiB) non-empty blocks including 1 (395.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 269.5 KiB, free 431.9 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.255.255.254:36873 (size: 269.5 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 72 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 76.0 (TID 61). 288622 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 61) in 12 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.019 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 61 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.022757 s\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 1278.1 KiB, free 430.6 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 350.8 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.255.255.254:36873 (size: 350.8 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 73 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:11:30 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:11:30 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Got job 62 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Final stage: ResultStage 78 (showString at <unknown>:0)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[176] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 17.0 KiB, free 430.3 MiB)\n",
      "24/08/19 23:11:30 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 430.3 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "|businessentityid|accountnumber|                name|creditrating|          city|\n",
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "|            1580|  LITWARE0001|       Litware, Inc.|           1|    Santa Cruz|\n",
      "|            1522|  FIRSTNA0001|First National Sp...|           1|         Boise|\n",
      "|            1618|  METROSP0001|Metro Sport Equip...|           1|       Lebanon|\n",
      "|            1650| AMERICAN0001|American Bicycles...|           1|   West Covina|\n",
      "|            1500|  MORGANB0001|Morgan Bike Acces...|           1|        Albany|\n",
      "|            1496| ADVANCED0001|   Advanced Bicycles|           1|      Lynnwood|\n",
      "|            1510| INTERNAT0001|       International|           1|Salt Lake City|\n",
      "|            1574|  JEFFSSP0001|Jeff's Sporting G...|           1|      Glendale|\n",
      "|            1634|   GMASKI0001|      GMA Ski & Bike|           1|     Bremerton|\n",
      "|            1564| ILLINOIS0001|Illinois Trek & C...|           1|   Mill Valley|\n",
      "|            1582|  INNERCI0001|    Inner City Bikes|           3|       W. Linn|\n",
      "|            1550|  MERITBI0001|         Merit Bikes|           5|     Bremerton|\n",
      "|            1506| GREENWOO0001|Greenwood Athleti...|           1|   Lemon Grove|\n",
      "|            1588| SIGNATUR0001|    Signature Cycles|           2|      Coronado|\n",
      "|            1512|  LIGHTSP0001|         Light Speed|           1| Spring Valley|\n",
      "|            1542|  HILLSBI0001|Hill's Bicycle Se...|           1|      Richmond|\n",
      "|            1586| MITCHELL0001|     Mitchell Sports|           1|       Everett|\n",
      "|            1694|  COMPETE0002|       Compete, Inc.|           1|        Dallas|\n",
      "|            1590| SUPERSAL0001|     SUPERSALES INC.|           1|      Lakewood|\n",
      "|            1626|  HILLBIC0001| Hill Bicycle Center|           1|       Oakland|\n",
      "+----------------+-------------+--------------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:11:30 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:11:30 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[176] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 62) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:11:30 INFO Executor: Running task 0.0 in stage 78.0 (TID 62)\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:11:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:11:30 INFO Executor: Finished task 0.0 in stage 78.0 (TID 62). 4671 bytes result sent to driver\n",
      "24/08/19 23:11:30 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 62) in 7 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:11:30 INFO DAGScheduler: ResultStage 78 (showString at <unknown>:0) finished in 0.010 s\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:11:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n",
      "24/08/19 23:11:30 INFO DAGScheduler: Job 62 finished: showString at <unknown>:0, took 0.014186 s\n"
     ]
    }
   ],
   "source": [
    "df_fornecedor_local.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e1c3772-f003-4b2d-bb95-76152901a01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Registering RDD 182 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 16\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Got map stage job 63 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[182] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 15.3 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.255.255.254:36873 (size: 7.9 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:11 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[182] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Registering RDD 184 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 17\n",
      "24/08/19 23:13:11 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 63) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:13:11 INFO DAGScheduler: Got map stage job 64 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Final stage: ShuffleMapStage 80 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:11 INFO Executor: Running task 0.0 in stage 79.0 (TID 63)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[184] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 13.9 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:11 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[184] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Registering RDD 186 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 18\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Got map stage job 65 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Final stage: ShuffleMapStage 81 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 81 (MapPartitionsRDD[186] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 14.6 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:13:11 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 81 (MapPartitionsRDD[186] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Registering RDD 188 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 19\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Got map stage job 66 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[188] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.4 KiB, free 430.2 MiB)\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 430.2 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.255.255.254:36873 (size: 7.6 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:13:11 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[188] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:11 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:13:11 INFO Executor: Finished task 0.0 in stage 79.0 (TID 63). 2034 bytes result sent to driver\n",
      "24/08/19 23:13:11 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 64) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:13:11 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 63) in 85 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:11 INFO Executor: Running task 0.0 in stage 80.0 (TID 64)\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:11 INFO DAGScheduler: ShuffleMapStage 79 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.091 s\n",
      "24/08/19 23:13:11 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:13:11 INFO DAGScheduler: running: Set(ShuffleMapStage 81, ShuffleMapStage 82, ShuffleMapStage 80)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:13:11 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:13:11 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Got job 67 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Final stage: ResultStage 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[190] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 8.2 KiB, free 430.2 MiB)\n",
      "24/08/19 23:13:11 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 430.2 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:13:11 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[190] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 10.255.255.254:36873 in memory (size: 350.8 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 10.255.255.254:36873 in memory (size: 4.7 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:13:11 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 10.255.255.254:36873 in memory (size: 269.5 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:11 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:13:11 INFO Executor: Finished task 0.0 in stage 80.0 (TID 64). 1948 bytes result sent to driver\n",
      "24/08/19 23:13:11 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 65) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:13:11 INFO Executor: Running task 0.0 in stage 81.0 (TID 65)\n",
      "24/08/19 23:13:11 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 64) in 160 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:11 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:11 INFO DAGScheduler: ShuffleMapStage 80 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.242 s\n",
      "24/08/19 23:13:11 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:13:11 INFO DAGScheduler: running: Set(ResultStage 84, ShuffleMapStage 81, ShuffleMapStage 82)\n",
      "24/08/19 23:13:11 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:13:11 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:13:11 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:13:11 INFO Executor: Finished task 0.0 in stage 81.0 (TID 65). 1948 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 66) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 65) in 134 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO Executor: Running task 0.0 in stage 82.0 (TID 66)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO DAGScheduler: ShuffleMapStage 81 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.345 s\n",
      "24/08/19 23:13:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:13:12 INFO DAGScheduler: running: Set(ResultStage 84, ShuffleMapStage 82)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:13:12 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:13:12 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:13:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Got job 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Final stage: ResultStage 86 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[192] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[192] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO Executor: Finished task 0.0 in stage 82.0 (TID 66). 2034 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 67) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:13:12 INFO Executor: Running task 0.0 in stage 84.0 (TID 67)\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 66) in 249 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: ShuffleMapStage 82 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.588 s\n",
      "24/08/19 23:13:12 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:13:12 INFO DAGScheduler: running: Set(ResultStage 84, ResultStage 86)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:13:12 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (10.8 KiB) non-empty blocks including 1 (10.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:13:12 INFO Executor: Finished task 0.0 in stage 84.0 (TID 67). 7721 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 68) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 67) in 10 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO Executor: Running task 0.0 in stage 86.0 (TID 68)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO DAGScheduler: ResultStage 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.522 s\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 67 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.524990 s\n",
      "24/08/19 23:13:12 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (262.2 KiB) non-empty blocks including 1 (262.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 1025.6 KiB, free 433.4 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 433.3 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.255.255.254:36873 (size: 4.7 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 81 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:12 INFO Executor: Finished task 0.0 in stage 86.0 (TID 68). 202260 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Got job 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Final stage: ResultStage 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[194] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 68) in 44 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.3 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[194] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:12 INFO DAGScheduler: ResultStage 86 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.284 s\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 69) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n",
      "24/08/19 23:13:12 INFO Executor: Running task 0.0 in stage 88.0 (TID 69)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 68 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.286776 s\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (395.4 KiB) non-empty blocks including 1 (395.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 1186.3 KiB, free 432.2 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 269.5 KiB, free 431.9 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.255.255.254:36873 (size: 269.5 KiB, free: 434.1 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 83 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:12 INFO Executor: Finished task 0.0 in stage 88.0 (TID 69). 288622 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 69) in 32 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO DAGScheduler: ResultStage 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.037 s\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 69 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.060652 s\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 1278.1 KiB, free 430.7 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 350.8 KiB, free 430.3 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.255.255.254:36873 (size: 350.8 KiB, free: 433.8 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 84 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:13:12 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:13:12 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:13:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:13:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:13:12 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Got job 70 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Final stage: ResultStage 90 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[197] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 219.9 KiB, free 430.1 MiB)\n",
      "24/08/19 23:13:12 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 430.0 MiB)\n",
      "24/08/19 23:13:12 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.255.255.254:36873 (size: 79.0 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:13:12 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[197] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 70) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:13:12 INFO Executor: Running task 0.0 in stage 90.0 (TID 70)\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:13:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:13:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:13:12 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:13:12 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:13:12 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:13:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"accountnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"creditrating\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(30)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary accountnumber (STRING);\n",
      "  optional binary name (STRING);\n",
      "  optional int32 creditrating (INTEGER(16,true));\n",
      "  optional binary city (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:13:12 INFO FileOutputCommitter: Saved output of task 'attempt_202408192313126229357642452396042_0090_m_000000_70' to file:/home/wallace/spark_case_adventure/gold/localizacao_fabricas.parquet/_temporary/0/task_202408192313126229357642452396042_0090_m_000000\n",
      "24/08/19 23:13:12 INFO SparkHadoopMapRedUtil: attempt_202408192313126229357642452396042_0090_m_000000_70: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:13:12 INFO Executor: Finished task 0.0 in stage 90.0 (TID 70). 5044 bytes result sent to driver\n",
      "24/08/19 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 70) in 46 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:13:12 INFO DAGScheduler: ResultStage 90 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.071 s\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:13:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "24/08/19 23:13:12 INFO DAGScheduler: Job 70 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.077572 s\n",
      "24/08/19 23:13:12 INFO FileFormatWriter: Start to commit write Job 04995e75-26aa-4500-8250-8f26b9e964bb.\n",
      "24/08/19 23:13:12 INFO FileFormatWriter: Write Job 04995e75-26aa-4500-8250-8f26b9e964bb committed. Elapsed time: 84 ms.\n",
      "24/08/19 23:13:12 INFO FileFormatWriter: Finished processing stats for write job 04995e75-26aa-4500-8250-8f26b9e964bb.\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 10.255.255.254:36873 in memory (size: 269.5 KiB, free: 434.0 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 10.255.255.254:36873 in memory (size: 7.6 KiB, free: 434.0 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 10.255.255.254:36873 in memory (size: 79.0 KiB, free: 434.0 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 10.255.255.254:36873 in memory (size: 350.8 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 10.255.255.254:36873 in memory (size: 4.7 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:27:30 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "df_fornecedor_local.write.mode(\"overwrite\").parquet(\"gold/localizacao_fabricas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "137d14c8-f0de-4643-bfff-be64ca92b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:41:09 INFO CodeGenerator: Code generated in 7.6332 ms\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Registering RDD 210 (showString at <unknown>:0) as input to shuffle 20\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Got map stage job 74 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (showString at <unknown>:0)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[210] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 16.4 KiB, free 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.255.255.254:36873 (size: 8.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[210] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:41:09 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Registering RDD 212 (showString at <unknown>:0) as input to shuffle 21\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Got map stage job 75 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (showString at <unknown>:0)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[212] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:41:09 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 74) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:41:09 INFO Executor: Running task 0.0 in stage 94.0 (TID 74)\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 13.9 KiB, free 434.3 MiB)\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 434.3 MiB)\n",
      "24/08/19 23:41:09 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[212] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:41:09 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:41:09 INFO CodeGenerator: Code generated in 7.8988 ms\n",
      "24/08/19 23:41:09 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:41:09 INFO Executor: Finished task 0.0 in stage 94.0 (TID 74). 1991 bytes result sent to driver\n",
      "24/08/19 23:41:09 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 75) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:41:09 INFO Executor: Running task 0.0 in stage 95.0 (TID 75)\n",
      "24/08/19 23:41:09 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 74) in 175 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:41:09 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:41:09 INFO DAGScheduler: ShuffleMapStage 94 (showString at <unknown>:0) finished in 0.196 s\n",
      "24/08/19 23:41:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:41:09 INFO DAGScheduler: running: Set(ShuffleMapStage 95)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:41:09 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:41:09 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 10.255.255.254:36873 in memory (size: 8.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Got job 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Final stage: ResultStage 97 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[214] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 8.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:41:09 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.3 MiB)\n",
      "24/08/19 23:41:09 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:41:09 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:41:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[214] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:41:09 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:41:09 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:41:09 INFO Executor: Finished task 0.0 in stage 95.0 (TID 75). 2034 bytes result sent to driver\n",
      "24/08/19 23:41:09 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 76) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:41:09 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 75) in 137 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:41:09 INFO Executor: Running task 0.0 in stage 97.0 (TID 76)\n",
      "24/08/19 23:41:09 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:41:09 INFO DAGScheduler: ShuffleMapStage 95 (showString at <unknown>:0) finished in 0.310 s\n",
      "24/08/19 23:41:09 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:41:09 INFO DAGScheduler: running: Set(ResultStage 97)\n",
      "24/08/19 23:41:09 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:41:09 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:41:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 10.255.255.254:36873 in memory (size: 7.9 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:41:10 INFO ShuffleBlockFetcherIterator: Getting 1 (739.9 KiB) non-empty blocks including 1 (739.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:41:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "24/08/19 23:41:10 INFO Executor: Finished task 0.0 in stage 97.0 (TID 76). 642015 bytes result sent to driver\n",
      "24/08/19 23:41:10 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 76) in 467 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:41:10 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:41:10 INFO DAGScheduler: ResultStage 97 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.518 s\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:41:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Job 76 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.523226 s\n",
      "24/08/19 23:41:10 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 2.2 MiB, free 432.2 MiB)\n",
      "24/08/19 23:41:10 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 721.1 KiB, free 431.5 MiB)\n",
      "24/08/19 23:41:10 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.255.255.254:36873 (size: 721.1 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:41:10 INFO SparkContext: Created broadcast 92 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:41:10 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:41:10 INFO CodeGenerator: Code generated in 9.0199 ms\n",
      "24/08/19 23:41:10 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Got job 77 (showString at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Final stage: ResultStage 99 (showString at <unknown>:0)\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[217] at showString at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:41:10 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 14.5 KiB, free 431.5 MiB)\n",
      "24/08/19 23:41:10 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 431.5 MiB)\n",
      "24/08/19 23:41:10 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.255.255.254:36873 (size: 6.7 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:41:10 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[217] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:41:10 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:41:10 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 77) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:41:10 INFO Executor: Running task 0.0 in stage 99.0 (TID 77)\n",
      "24/08/19 23:41:10 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:41:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:41:10 INFO CodeGenerator: Code generated in 6.7902 ms\n",
      "24/08/19 23:41:10 INFO Executor: Finished task 0.0 in stage 99.0 (TID 77). 4183 bytes result sent to driver\n",
      "24/08/19 23:41:10 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 77) in 15 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:41:10 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:41:10 INFO DAGScheduler: ResultStage 99 (showString at <unknown>:0) finished in 0.024 s\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:41:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished\n",
      "24/08/19 23:41:10 INFO DAGScheduler: Job 77 finished: showString at <unknown>:0, took 0.029301 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------+----------+----------+\n",
      "|businessentityid|persontype|firstname|middlename|  lastname|\n",
      "+----------------+----------+---------+----------+----------+\n",
      "|             148|        EM|    Jason|         M|   Watters|\n",
      "|             463|        SC|Alexander|        J.|    Berger|\n",
      "|             471|        SC|   Robert|        M.| Bernacchi|\n",
      "|             833|        SC|     Tish|        R.|      Duff|\n",
      "|            1591|        VC|  Michael|      NULL|    Patten|\n",
      "|            1645|        VC|     Sean|      NULL|   Purcell|\n",
      "|            1829|        SC|      Min|      NULL|        Su|\n",
      "|            1959|        SC|    Roger|      NULL|Van Houten|\n",
      "|            2122|        GC|    Brian|      NULL|     Groth|\n",
      "|            2142|        GC|  Annette|      NULL|      Hill|\n",
      "|            2366|        GC|    David|      NULL|   Daniels|\n",
      "|            2659|        IN|  Tiffany|         K|      Yang|\n",
      "|            2866|        IN|   Sydney|      NULL|   Sanders|\n",
      "|            3175|        IN|  Adriana|      NULL|    Subram|\n",
      "|            3749|        IN|   Edward|      NULL|   Edwards|\n",
      "|            3794|        IN|    Wyatt|         S| Hernandez|\n",
      "|            3918|        IN|  Abigail|         R|      Reed|\n",
      "|            3997|        IN|   Jeremy|      NULL|     White|\n",
      "|            4101|        IN|   Miguel|      NULL|     Lewis|\n",
      "|            4519|        IN|   Dalton|      NULL|  Phillips|\n",
      "+----------------+----------+---------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b. Informações de perfil de consumo da demanda;\n",
    "df_perfil = df_pessoa.join(df_bussiness,'businessentityid','inner').select(df_pessoa.businessentityid,df_pessoa.persontype,df_pessoa.firstname,df_pessoa.middlename,df_pessoa.lastname)\n",
    "\n",
    "df_perfil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "85e258ec-8e8a-4847-96d2-693ebb616a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:42:22 INFO DAGScheduler: Registering RDD 221 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 22\n",
      "24/08/19 23:42:22 INFO DAGScheduler: Got map stage job 78 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:42:22 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:42:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:42:22 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[221] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 16.4 KiB, free 431.5 MiB)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.5 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.255.255.254:36873 (size: 8.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[221] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Registering RDD 223 (parquet at NativeMethodAccessorImpl.java:0) as input to shuffle 23\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Got map stage job 79 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 78) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:42:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[223] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:42:23 INFO Executor: Running task 0.0 in stage 100.0 (TID 78)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 13.9 KiB, free 431.4 MiB)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 431.4 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[223] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:23 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:42:23 INFO Executor: Finished task 0.0 in stage 100.0 (TID 78). 1948 bytes result sent to driver\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 79) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:42:23 INFO Executor: Running task 0.0 in stage 101.0 (TID 79)\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 78) in 88 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:23 INFO DAGScheduler: ShuffleMapStage 100 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.164 s\n",
      "24/08/19 23:42:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:42:23 INFO DAGScheduler: running: Set(ShuffleMapStage 101)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:42:23 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:42:23 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Got job 80 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Final stage: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[225] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KiB, free 431.4 MiB)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 431.4 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[225] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 10.255.255.254:36873 in memory (size: 6.7 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 10.255.255.254:36873 in memory (size: 8.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:42:23 INFO Executor: Finished task 0.0 in stage 101.0 (TID 79). 2034 bytes result sent to driver\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 80) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:42:23 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 79) in 105 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:23 INFO Executor: Running task 0.0 in stage 103.0 (TID 80)\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:23 INFO DAGScheduler: ShuffleMapStage 101 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.188 s\n",
      "24/08/19 23:42:23 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:42:23 INFO DAGScheduler: running: Set(ResultStage 103)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:42:23 INFO ShuffleBlockFetcherIterator: Getting 1 (739.9 KiB) non-empty blocks including 1 (739.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:42:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:42:23 INFO Executor: Finished task 0.0 in stage 103.0 (TID 80). 641972 bytes result sent to driver\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 80) in 16 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:23 INFO DAGScheduler: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.103 s\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Job 80 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.105645 s\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 2.2 MiB, free 429.3 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 721.1 KiB, free 428.6 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.255.255.254:36873 (size: 721.1 KiB, free: 433.0 MiB)\n",
      "24/08/19 23:42:23 INFO SparkContext: Created broadcast 97 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 10.255.255.254:36873 in memory (size: 721.1 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:23 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:42:23 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:23 INFO CodeGenerator: Code generated in 8.1604 ms\n",
      "24/08/19 23:42:23 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Got job 81 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Final stage: ResultStage 105 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[228] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 217.5 KiB, free 431.3 MiB)\n",
      "24/08/19 23:42:23 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 78.5 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:23 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.255.255.254:36873 (size: 78.5 KiB, free: 433.6 MiB)\n",
      "24/08/19 23:42:23 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[228] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 81) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:42:23 INFO Executor: Running task 0.0 in stage 105.0 (TID 81)\n",
      "24/08/19 23:42:23 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:42:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:42:23 INFO CodeGenerator: Code generated in 5.7103 ms\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:23 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:42:23 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:42:23 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:42:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"persontype\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"firstname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"middlename\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"lastname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary persontype (STRING);\n",
      "  optional binary firstname (STRING);\n",
      "  optional binary middlename (STRING);\n",
      "  optional binary lastname (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:42:23 INFO FileOutputCommitter: Saved output of task 'attempt_202408192342232574491470571513739_0105_m_000000_81' to file:/home/wallace/spark_case_adventure/silver/perfil.parquet/_temporary/0/task_202408192342232574491470571513739_0105_m_000000\n",
      "24/08/19 23:42:23 INFO SparkHadoopMapRedUtil: attempt_202408192342232574491470571513739_0105_m_000000_81: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:42:23 INFO Executor: Finished task 0.0 in stage 105.0 (TID 81). 4932 bytes result sent to driver\n",
      "24/08/19 23:42:23 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 81) in 133 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:23 INFO DAGScheduler: ResultStage 105 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.153 s\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:42:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "24/08/19 23:42:23 INFO DAGScheduler: Job 81 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.155903 s\n",
      "24/08/19 23:42:23 INFO FileFormatWriter: Start to commit write Job 667a2572-19b1-40e4-be08-0329edd0fd40.\n",
      "24/08/19 23:42:23 INFO FileFormatWriter: Write Job 667a2572-19b1-40e4-be08-0329edd0fd40 committed. Elapsed time: 29 ms.\n",
      "24/08/19 23:42:23 INFO FileFormatWriter: Finished processing stats for write job 667a2572-19b1-40e4-be08-0329edd0fd40.\n"
     ]
    }
   ],
   "source": [
    "df_perfil.write.mode(\"overwrite\").parquet(\"silver/perfil.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "36412c4b-5933-4a86-a7f7-37dff4fcc076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/19 23:42:53 INFO DAGScheduler: Registering RDD 232 (parquet at <unknown>:0) as input to shuffle 24\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Got map stage job 82 (parquet at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Final stage: ShuffleMapStage 106 (parquet at <unknown>:0)\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[232] at parquet at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:42:53 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 16.4 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:53 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.255.255.254:36873 (size: 8.2 KiB, free: 433.6 MiB)\n",
      "24/08/19 23:42:53 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[232] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:53 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Registering RDD 234 (parquet at <unknown>:0) as input to shuffle 25\n",
      "24/08/19 23:42:53 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 82) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:42:53 INFO DAGScheduler: Got map stage job 83 (parquet at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Final stage: ShuffleMapStage 107 (parquet at <unknown>:0)\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:53 INFO Executor: Running task 0.0 in stage 106.0 (TID 82)\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[234] at parquet at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:42:53 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 13.9 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:53 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.255.255.254:36873 (size: 7.3 KiB, free: 433.6 MiB)\n",
      "24/08/19 23:42:53 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[234] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:53 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:54 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:42:54 INFO Executor: Finished task 0.0 in stage 106.0 (TID 82). 1948 bytes result sent to driver\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 83) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7450 bytes) \n",
      "24/08/19 23:42:54 INFO Executor: Running task 0.0 in stage 107.0 (TID 83)\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 82) in 188 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:54 INFO DAGScheduler: ShuffleMapStage 106 (parquet at <unknown>:0) finished in 0.203 s\n",
      "24/08/19 23:42:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:42:54 INFO DAGScheduler: running: Set(ShuffleMapStage 107)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:42:54 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:42:54 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:42:54 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Got job 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Final stage: ResultStage 109 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 10.255.255.254:36873 in memory (size: 8.2 KiB, free: 433.6 MiB)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[236] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 8.2 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 431.3 MiB)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 10.255.255.254:36873 in memory (size: 78.5 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.255.255.254:36873 (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:54 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[236] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:54 INFO JDBCRDD: closed connection\n",
      "24/08/19 23:42:54 INFO Executor: Finished task 0.0 in stage 107.0 (TID 83). 2034 bytes result sent to driver\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 84) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:42:54 INFO Executor: Running task 0.0 in stage 109.0 (TID 84)\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 83) in 101 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:54 INFO DAGScheduler: ShuffleMapStage 107 (parquet at <unknown>:0) finished in 0.284 s\n",
      "24/08/19 23:42:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/19 23:42:54 INFO DAGScheduler: running: Set(ResultStage 109)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: waiting: Set()\n",
      "24/08/19 23:42:54 INFO DAGScheduler: failed: Set()\n",
      "24/08/19 23:42:54 INFO ShuffleBlockFetcherIterator: Getting 1 (739.9 KiB) non-empty blocks including 1 (739.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:42:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:42:54 INFO Executor: Finished task 0.0 in stage 109.0 (TID 84). 641972 bytes result sent to driver\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 84) in 17 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:54 INFO DAGScheduler: ResultStage 109 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.084 s\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Job 84 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.086904 s\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 2.2 MiB, free 429.3 MiB)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 721.1 KiB, free 428.6 MiB)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.255.255.254:36873 (size: 721.1 KiB, free: 433.0 MiB)\n",
      "24/08/19 23:42:54 INFO SparkContext: Created broadcast 102 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.0 MiB)\n",
      "24/08/19 23:42:54 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 10.255.255.254:36873 in memory (size: 721.1 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:42:54 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:54 INFO SparkContext: Starting job: parquet at <unknown>:0\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Got job 85 (parquet at <unknown>:0) with 1 output partitions\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Final stage: ResultStage 111 (parquet at <unknown>:0)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[239] at parquet at <unknown>:0), which has no missing parents\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 217.5 KiB, free 431.3 MiB)\n",
      "24/08/19 23:42:54 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 78.5 KiB, free 431.2 MiB)\n",
      "24/08/19 23:42:54 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.255.255.254:36873 (size: 78.5 KiB, free: 433.6 MiB)\n",
      "24/08/19 23:42:54 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[239] at parquet at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 85) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7634 bytes) \n",
      "24/08/19 23:42:54 INFO Executor: Running task 0.0 in stage 111.0 (TID 85)\n",
      "24/08/19 23:42:54 INFO ShuffleBlockFetcherIterator: Getting 1 (187.2 KiB) non-empty blocks including 1 (187.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/19 23:42:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/19 23:42:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/19 23:42:54 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:42:54 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/19 23:42:54 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/19 23:42:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"businessentityid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"persontype\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"firstname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"middlename\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"lastname\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 businessentityid;\n",
      "  optional binary persontype (STRING);\n",
      "  optional binary firstname (STRING);\n",
      "  optional binary middlename (STRING);\n",
      "  optional binary lastname (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/19 23:42:54 INFO FileOutputCommitter: Saved output of task 'attempt_202408192342542812656807100614093_0111_m_000000_85' to file:/home/wallace/spark_case_adventure/gold/perfil.parquet/_temporary/0/task_202408192342542812656807100614093_0111_m_000000\n",
      "24/08/19 23:42:54 INFO SparkHadoopMapRedUtil: attempt_202408192342542812656807100614093_0111_m_000000_85: Committed. Elapsed time: 0 ms.\n",
      "24/08/19 23:42:54 INFO Executor: Finished task 0.0 in stage 111.0 (TID 85). 4932 bytes result sent to driver\n",
      "24/08/19 23:42:54 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 85) in 118 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "24/08/19 23:42:54 INFO DAGScheduler: ResultStage 111 (parquet at <unknown>:0) finished in 0.167 s\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/19 23:42:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished\n",
      "24/08/19 23:42:54 INFO DAGScheduler: Job 85 finished: parquet at <unknown>:0, took 0.196702 s\n",
      "24/08/19 23:42:54 INFO FileFormatWriter: Start to commit write Job 903c102a-82e0-4cb7-bb8c-bb5fa2bfa262.\n",
      "24/08/19 23:42:54 INFO FileFormatWriter: Write Job 903c102a-82e0-4cb7-bb8c-bb5fa2bfa262 committed. Elapsed time: 13 ms.\n",
      "24/08/19 23:42:54 INFO FileFormatWriter: Finished processing stats for write job 903c102a-82e0-4cb7-bb8c-bb5fa2bfa262.\n",
      "24/08/19 23:57:30 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 10.255.255.254:36873 in memory (size: 78.5 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:57:30 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 10.255.255.254:36873 in memory (size: 4.2 KiB, free: 433.7 MiB)\n",
      "24/08/19 23:57:30 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 10.255.255.254:36873 in memory (size: 721.1 KiB, free: 434.4 MiB)\n",
      "24/08/19 23:57:30 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 10.255.255.254:36873 in memory (size: 7.3 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "df_perfil.write.mode(\"overwrite\").parquet(\"gold/perfil.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7384675-95d9-4be3-aeb3-6c911b735636",
   "metadata": {},
   "source": [
    "#Lendo consulta de produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b016bd4b-27cf-4155-957a-da0ddd5c7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produtos = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/Adventureworks\")\\\n",
    "    .option(\"dbtable\", \"production.product\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e5867bc-0faf-4bdb-ba23-9eb0c3d13436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- productid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- productnumber: string (nullable = true)\n",
      " |-- makeflag: boolean (nullable = true)\n",
      " |-- finishedgoodsflag: boolean (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- safetystocklevel: short (nullable = true)\n",
      " |-- reorderpoint: short (nullable = true)\n",
      " |-- standardcost: decimal(38,18) (nullable = true)\n",
      " |-- listprice: decimal(38,18) (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- sizeunitmeasurecode: string (nullable = true)\n",
      " |-- weightunitmeasurecode: string (nullable = true)\n",
      " |-- weight: decimal(8,2) (nullable = true)\n",
      " |-- daystomanufacture: integer (nullable = true)\n",
      " |-- productline: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- style: string (nullable = true)\n",
      " |-- productsubcategoryid: integer (nullable = true)\n",
      " |-- productmodelid: integer (nullable = true)\n",
      " |-- sellstartdate: timestamp (nullable = true)\n",
      " |-- sellenddate: timestamp (nullable = true)\n",
      " |-- discontinueddate: timestamp (nullable = true)\n",
      " |-- rowguid: string (nullable = true)\n",
      " |-- modifieddate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_produtos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "883d800d-0b8d-4774-9078-cf69131c1556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 08:55:57 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:55:57 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Got job 23 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[73] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 08:55:57 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 227.7 KiB, free 433.9 MiB)\n",
      "24/08/20 08:55:57 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 81.2 KiB, free 434.0 MiB)\n",
      "24/08/20 08:55:57 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.255.255.254:32855 in memory (size: 36.1 KiB, free: 434.4 MiB)\n",
      "24/08/20 08:55:57 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.255.255.254:32855 (size: 81.2 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:55:57 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[73] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 08:55:57 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "24/08/20 08:55:57 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.255.255.254:32855 in memory (size: 11.1 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:55:57 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 23) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/20 08:55:57 INFO Executor: Running task 0.0 in stage 26.0 (TID 23)\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:55:57 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 08:55:57 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 08:55:57 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/20 08:55:57 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"productid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(25)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"makeflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"finishedgoodsflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"color\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"safetystocklevel\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"reorderpoint\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"standardcost\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"listprice\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"size\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(5)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sizeunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weightunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weight\",\n",
      "    \"type\" : \"decimal(8,2)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 2\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"daystomanufacture\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productline\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"class\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"style\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productsubcategoryid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productmodelid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellstartdate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellenddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"discontinueddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 productid;\n",
      "  optional binary name (STRING);\n",
      "  optional binary productnumber (STRING);\n",
      "  optional boolean makeflag;\n",
      "  optional boolean finishedgoodsflag;\n",
      "  optional binary color (STRING);\n",
      "  optional int32 safetystocklevel (INTEGER(16,true));\n",
      "  optional int32 reorderpoint (INTEGER(16,true));\n",
      "  optional fixed_len_byte_array(16) standardcost (DECIMAL(38,18));\n",
      "  optional fixed_len_byte_array(16) listprice (DECIMAL(38,18));\n",
      "  optional binary size (STRING);\n",
      "  optional binary sizeunitmeasurecode (STRING);\n",
      "  optional binary weightunitmeasurecode (STRING);\n",
      "  optional int32 weight (DECIMAL(8,2));\n",
      "  optional int32 daystomanufacture;\n",
      "  optional binary productline (STRING);\n",
      "  optional binary class (STRING);\n",
      "  optional binary style (STRING);\n",
      "  optional int32 productsubcategoryid;\n",
      "  optional int32 productmodelid;\n",
      "  optional int96 sellstartdate;\n",
      "  optional int96 sellenddate;\n",
      "  optional int96 discontinueddate;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/20 08:55:57 INFO JDBCRDD: closed connection\n",
      "24/08/20 08:55:57 INFO FileOutputCommitter: Saved output of task 'attempt_20240820085557509772300601504925_0026_m_000000_23' to file:/home/wallace/spark_case_adventure/bronze/produtos_lucros.parquet/_temporary/0/task_20240820085557509772300601504925_0026_m_000000\n",
      "24/08/20 08:55:57 INFO SparkHadoopMapRedUtil: attempt_20240820085557509772300601504925_0026_m_000000_23: Committed. Elapsed time: 1 ms.\n",
      "24/08/20 08:55:57 INFO Executor: Finished task 0.0 in stage 26.0 (TID 23). 2527 bytes result sent to driver\n",
      "24/08/20 08:55:57 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 23) in 319 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 08:55:57 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "24/08/20 08:55:57 INFO DAGScheduler: ResultStage 26 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.384 s\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 08:55:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "24/08/20 08:55:57 INFO DAGScheduler: Job 23 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.394549 s\n",
      "24/08/20 08:55:57 INFO FileFormatWriter: Start to commit write Job 5d2455c1-2c40-40af-873d-02e391d2c12d.\n",
      "24/08/20 08:55:57 INFO FileFormatWriter: Write Job 5d2455c1-2c40-40af-873d-02e391d2c12d committed. Elapsed time: 84 ms.\n",
      "24/08/20 08:55:57 INFO FileFormatWriter: Finished processing stats for write job 5d2455c1-2c40-40af-873d-02e391d2c12d.\n"
     ]
    }
   ],
   "source": [
    "df_produtos.write.mode(\"overwrite\").parquet(\"bronze/produtos_lucros.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "537020ba-3691-429b-9021-9f3127508c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 09:07:02 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/08/20 09:07:02 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/08/20 09:07:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 201.7 KiB, free 433.9 MiB)\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 35.3 KiB, free 433.9 MiB)\n",
      "24/08/20 09:07:02 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.255.255.254:32855 (size: 35.3 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:07:02 INFO SparkContext: Created broadcast 42 from showString at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 09:07:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4235576 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Registering RDD 102 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Got map stage job 32 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Final stage: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[102] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 38.3 KiB, free 433.9 MiB)\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 433.8 MiB)\n",
      "24/08/20 09:07:02 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.255.255.254:32855 (size: 17.1 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:07:02 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[102] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 09:07:02 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "24/08/20 09:07:02 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 32) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 8305 bytes) \n",
      "24/08/20 09:07:02 INFO Executor: Running task 0.0 in stage 36.0 (TID 32)\n",
      "24/08/20 09:07:02 INFO FileScanRDD: Reading File path: file:///home/wallace/spark_case_adventure/gold/produtos_lucros.parquet/part-00000-c3f1e7be-8df6-4d85-bcbf-570f5e18df7c-c000.snappy.parquet, range: 0-41272, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+\n",
      "|productid|                name| menos_vendidos_mais|\n",
      "+---------+--------------------+--------------------+\n",
      "|      960|Touring-3000 Blue...|742.3500000000000...|\n",
      "|      316|               Blade|0.000000000000000000|\n",
      "|      809|ML Mountain Handl...|61.92000000000000...|\n",
      "|      966|Touring-1000 Blue...|2384.070000000000...|\n",
      "|      970|Touring-2000 Blue...|1214.850000000000...|\n",
      "|      348|       Flat Washer 5|0.000000000000000000|\n",
      "|      477|         Metal Bar 1|0.000000000000000000|\n",
      "|      880|Hydration Pack - ...|54.99000000000000...|\n",
      "|      409|External Lock Was...|0.000000000000000000|\n",
      "|      784|Mountain-200 Blac...|2294.990000000000...|\n",
      "|      885|HL Touring Frame ...|1003.910000000000...|\n",
      "|      398|      Handlebar Tube|0.000000000000000000|\n",
      "|      895|LL Touring Frame ...|333.4200000000000...|\n",
      "|      759|    Road-650 Red, 58|782.9900000000000...|\n",
      "|      996|   HL Bottom Bracket|121.4900000000000...|\n",
      "|      330|    Touring End Caps|0.000000000000000000|\n",
      "|      329|       Road End Caps|0.000000000000000000|\n",
      "|      526|            HL Shell|0.000000000000000000|\n",
      "|      771|Mountain-100 Silv...|3399.990000000000...|\n",
      "|      376|           Hex Nut 6|0.000000000000000000|\n",
      "+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 09:07:02 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.255.255.254:32855 in memory (size: 11.1 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:07:02 INFO Executor: Finished task 0.0 in stage 36.0 (TID 32). 3018 bytes result sent to driver\n",
      "24/08/20 09:07:02 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 32) in 241 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 09:07:02 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "24/08/20 09:07:02 INFO DAGScheduler: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 0.266 s\n",
      "24/08/20 09:07:02 INFO DAGScheduler: looking for newly runnable stages\n",
      "24/08/20 09:07:02 INFO DAGScheduler: running: Set()\n",
      "24/08/20 09:07:02 INFO DAGScheduler: waiting: Set()\n",
      "24/08/20 09:07:02 INFO DAGScheduler: failed: Set()\n",
      "24/08/20 09:07:02 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "24/08/20 09:07:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "24/08/20 09:07:02 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Got job 33 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Final stage: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 45.5 KiB, free 433.8 MiB)\n",
      "24/08/20 09:07:02 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 433.8 MiB)\n",
      "24/08/20 09:07:02 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.255.255.254:32855 (size: 20.6 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:07:02 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 09:07:02 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "24/08/20 09:07:02 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 33) (10.255.255.254, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "24/08/20 09:07:02 INFO Executor: Running task 0.0 in stage 38.0 (TID 33)\n",
      "24/08/20 09:07:02 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.255.255.254:32855 in memory (size: 36.1 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:07:02 INFO ShuffleBlockFetcherIterator: Getting 1 (35.6 KiB) non-empty blocks including 1 (35.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "24/08/20 09:07:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "24/08/20 09:07:02 INFO Executor: Finished task 0.0 in stage 38.0 (TID 33). 6135 bytes result sent to driver\n",
      "24/08/20 09:07:02 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 33) in 31 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 09:07:02 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "24/08/20 09:07:02 INFO DAGScheduler: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0) finished in 0.037 s\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 09:07:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "24/08/20 09:07:02 INFO DAGScheduler: Job 33 finished: showString at NativeMethodAccessorImpl.java:0, took 0.045278 s\n"
     ]
    }
   ],
   "source": [
    "#a. Identificação de produtos mais lucrativos;\n",
    "#b. Identificação de produtos menos lucrativos.\n",
    "df_produtos.groupby(\"productid\",\"name\").agg(sum(\"listprice\").alias(\"menos_vendidos_mais\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb2339e1-3dfc-43b7-a9ce-70363fb220a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 08:56:08 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:56:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:56:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:56:08 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Got job 26 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Final stage: ResultStage 30 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[82] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 08:56:08 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 227.7 KiB, free 434.1 MiB)\n",
      "24/08/20 08:56:08 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 81.2 KiB, free 434.0 MiB)\n",
      "24/08/20 08:56:08 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.255.255.254:32855 (size: 81.2 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:56:08 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[82] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 08:56:08 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "24/08/20 08:56:08 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 26) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7461 bytes) \n",
      "24/08/20 08:56:08 INFO Executor: Running task 0.0 in stage 30.0 (TID 26)\n",
      "24/08/20 08:56:08 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.255.255.254:32855 in memory (size: 20.5 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:56:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 08:56:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 08:56:08 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 08:56:08 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 08:56:08 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/20 08:56:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"productid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(25)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"makeflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"finishedgoodsflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"color\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"safetystocklevel\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"reorderpoint\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"standardcost\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"listprice\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"size\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(5)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sizeunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weightunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weight\",\n",
      "    \"type\" : \"decimal(8,2)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 2\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"daystomanufacture\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productline\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"class\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"style\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productsubcategoryid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productmodelid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellstartdate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellenddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"discontinueddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 productid;\n",
      "  optional binary name (STRING);\n",
      "  optional binary productnumber (STRING);\n",
      "  optional boolean makeflag;\n",
      "  optional boolean finishedgoodsflag;\n",
      "  optional binary color (STRING);\n",
      "  optional int32 safetystocklevel (INTEGER(16,true));\n",
      "  optional int32 reorderpoint (INTEGER(16,true));\n",
      "  optional fixed_len_byte_array(16) standardcost (DECIMAL(38,18));\n",
      "  optional fixed_len_byte_array(16) listprice (DECIMAL(38,18));\n",
      "  optional binary size (STRING);\n",
      "  optional binary sizeunitmeasurecode (STRING);\n",
      "  optional binary weightunitmeasurecode (STRING);\n",
      "  optional int32 weight (DECIMAL(8,2));\n",
      "  optional int32 daystomanufacture;\n",
      "  optional binary productline (STRING);\n",
      "  optional binary class (STRING);\n",
      "  optional binary style (STRING);\n",
      "  optional int32 productsubcategoryid;\n",
      "  optional int32 productmodelid;\n",
      "  optional int96 sellstartdate;\n",
      "  optional int96 sellenddate;\n",
      "  optional int96 discontinueddate;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/20 08:56:08 INFO JDBCRDD: closed connection\n",
      "24/08/20 08:56:08 INFO FileOutputCommitter: Saved output of task 'attempt_202408200856083567303614266078739_0030_m_000000_26' to file:/home/wallace/spark_case_adventure/silver/produtos_lucros.parquet/_temporary/0/task_202408200856083567303614266078739_0030_m_000000\n",
      "24/08/20 08:56:08 INFO SparkHadoopMapRedUtil: attempt_202408200856083567303614266078739_0030_m_000000_26: Committed. Elapsed time: 1 ms.\n",
      "24/08/20 08:56:08 INFO Executor: Finished task 0.0 in stage 30.0 (TID 26). 2570 bytes result sent to driver\n",
      "24/08/20 08:56:08 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 26) in 185 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 08:56:08 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "24/08/20 08:56:08 INFO DAGScheduler: ResultStage 30 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.232 s\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 08:56:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "24/08/20 08:56:08 INFO DAGScheduler: Job 26 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.245782 s\n",
      "24/08/20 08:56:08 INFO FileFormatWriter: Start to commit write Job 40e3deb4-200a-4967-b709-c645c5c0e2a6.\n",
      "24/08/20 08:56:08 INFO FileFormatWriter: Write Job 40e3deb4-200a-4967-b709-c645c5c0e2a6 committed. Elapsed time: 75 ms.\n",
      "24/08/20 08:56:08 INFO FileFormatWriter: Finished processing stats for write job 40e3deb4-200a-4967-b709-c645c5c0e2a6.\n"
     ]
    }
   ],
   "source": [
    "df_produtos.write.mode(\"overwrite\").parquet(\"silver/produtos_lucros.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76a900f0-5e13-44f5-848a-87b7feb513f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 08:56:13 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.\n",
      "24/08/20 08:56:13 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Got job 27 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[84] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 08:56:13 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 103.6 KiB, free 433.9 MiB)\n",
      "24/08/20 08:56:13 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.9 MiB)\n",
      "24/08/20 08:56:13 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.255.255.254:32855 (size: 37.4 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:56:13 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[84] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 08:56:13 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "24/08/20 08:56:13 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 27) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7848 bytes) \n",
      "24/08/20 08:56:13 INFO Executor: Running task 0.0 in stage 31.0 (TID 27)\n",
      "24/08/20 08:56:13 INFO Executor: Finished task 0.0 in stage 31.0 (TID 27). 3632 bytes result sent to driver\n",
      "24/08/20 08:56:13 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 27) in 26 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 08:56:13 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "24/08/20 08:56:13 INFO DAGScheduler: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.053 s\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 08:56:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "24/08/20 08:56:13 INFO DAGScheduler: Job 27 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.062385 s\n",
      "24/08/20 08:56:13 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.255.255.254:32855 in memory (size: 15.8 KiB, free: 434.3 MiB)\n",
      "24/08/20 08:56:13 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.255.255.254:32855 in memory (size: 81.2 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "df_produtos = spark.read.parquet(\"silver/produtos_lucros.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00c9fb80-452b-49a2-a790-240a46ac72be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 09:04:01 INFO FileSourceStrategy: Pushed Filters: \n",
      "24/08/20 09:04:01 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "24/08/20 09:04:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 09:04:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 09:04:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 09:04:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 09:04:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 09:04:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 09:04:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 09:04:02 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 205.2 KiB, free 434.0 MiB)\n",
      "24/08/20 09:04:02 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 433.9 MiB)\n",
      "24/08/20 09:04:02 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.255.255.254:32855 (size: 36.1 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:04:02 INFO SparkContext: Created broadcast 37 from parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 09:04:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4235576 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "24/08/20 09:04:02 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Got job 29 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Final stage: ResultStage 33 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[92] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 09:04:02 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.255.255.254:32855 in memory (size: 36.1 KiB, free: 434.4 MiB)\n",
      "24/08/20 09:04:02 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 237.9 KiB, free 433.9 MiB)\n",
      "24/08/20 09:04:02 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 82.0 KiB, free 433.9 MiB)\n",
      "24/08/20 09:04:02 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.255.255.254:32855 (size: 82.0 KiB, free: 434.3 MiB)\n",
      "24/08/20 09:04:02 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[92] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 09:04:02 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "24/08/20 09:04:02 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 29) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 8318 bytes) \n",
      "24/08/20 09:04:02 INFO Executor: Running task 0.0 in stage 33.0 (TID 29)\n",
      "24/08/20 09:04:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 09:04:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 09:04:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 09:04:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "24/08/20 09:04:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "24/08/20 09:04:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "24/08/20 09:04:02 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 09:04:02 INFO CodecConfig: Compression: SNAPPY\n",
      "24/08/20 09:04:02 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]\n",
      "24/08/20 09:04:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"productid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(50)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productnumber\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(25)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"makeflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"finishedgoodsflag\",\n",
      "    \"type\" : \"boolean\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"color\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(15)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"safetystocklevel\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"reorderpoint\",\n",
      "    \"type\" : \"short\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"standardcost\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"listprice\",\n",
      "    \"type\" : \"decimal(38,18)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"size\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"varchar(5)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sizeunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weightunitmeasurecode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(3)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"weight\",\n",
      "    \"type\" : \"decimal(8,2)\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 2\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"daystomanufacture\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productline\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"class\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"style\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"__CHAR_VARCHAR_TYPE_STRING\" : \"char(2)\",\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productsubcategoryid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"productmodelid\",\n",
      "    \"type\" : \"integer\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellstartdate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"sellenddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"discontinueddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"rowguid\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 0\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"modifieddate\",\n",
      "    \"type\" : \"timestamp\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : {\n",
      "      \"scale\" : 6\n",
      "    }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional int32 productid;\n",
      "  optional binary name (STRING);\n",
      "  optional binary productnumber (STRING);\n",
      "  optional boolean makeflag;\n",
      "  optional boolean finishedgoodsflag;\n",
      "  optional binary color (STRING);\n",
      "  optional int32 safetystocklevel (INTEGER(16,true));\n",
      "  optional int32 reorderpoint (INTEGER(16,true));\n",
      "  optional fixed_len_byte_array(16) standardcost (DECIMAL(38,18));\n",
      "  optional fixed_len_byte_array(16) listprice (DECIMAL(38,18));\n",
      "  optional binary size (STRING);\n",
      "  optional binary sizeunitmeasurecode (STRING);\n",
      "  optional binary weightunitmeasurecode (STRING);\n",
      "  optional int32 weight (DECIMAL(8,2));\n",
      "  optional int32 daystomanufacture;\n",
      "  optional binary productline (STRING);\n",
      "  optional binary class (STRING);\n",
      "  optional binary style (STRING);\n",
      "  optional int32 productsubcategoryid;\n",
      "  optional int32 productmodelid;\n",
      "  optional int96 sellstartdate;\n",
      "  optional int96 sellenddate;\n",
      "  optional int96 discontinueddate;\n",
      "  optional binary rowguid (STRING);\n",
      "  optional int96 modifieddate;\n",
      "}\n",
      "\n",
      "       \n",
      "24/08/20 09:04:02 INFO FileScanRDD: Reading File path: file:///home/wallace/spark_case_adventure/silver/produtos_lucros.parquet/part-00000-5468aa81-83bb-4415-82f1-caa2d46421ec-c000.snappy.parquet, range: 0-41272, partition values: [empty row]\n",
      "24/08/20 09:04:02 INFO FileOutputCommitter: Saved output of task 'attempt_202408200904028313943691227560078_0033_m_000000_29' to file:/home/wallace/spark_case_adventure/gold/produtos_lucros.parquet/_temporary/0/task_202408200904028313943691227560078_0033_m_000000\n",
      "24/08/20 09:04:02 INFO SparkHadoopMapRedUtil: attempt_202408200904028313943691227560078_0033_m_000000_29: Committed. Elapsed time: 1 ms.\n",
      "24/08/20 09:04:02 INFO Executor: Finished task 0.0 in stage 33.0 (TID 29). 2778 bytes result sent to driver\n",
      "24/08/20 09:04:02 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 29) in 173 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 09:04:02 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "24/08/20 09:04:02 INFO DAGScheduler: ResultStage 33 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.272 s\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 09:04:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "24/08/20 09:04:02 INFO DAGScheduler: Job 29 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.278974 s\n",
      "24/08/20 09:04:02 INFO FileFormatWriter: Start to commit write Job ddcaee8f-2c08-4e68-aa47-4a3a40e54100.\n",
      "24/08/20 09:04:02 INFO FileFormatWriter: Write Job ddcaee8f-2c08-4e68-aa47-4a3a40e54100 committed. Elapsed time: 55 ms.\n",
      "24/08/20 09:04:02 INFO FileFormatWriter: Finished processing stats for write job ddcaee8f-2c08-4e68-aa47-4a3a40e54100.\n"
     ]
    }
   ],
   "source": [
    "df_produtos.write.mode(\"overwrite\").parquet(\"gold/produtos_lucros.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a749857-c1f3-45c2-afd6-ed23ac68ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/20 09:04:58 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n",
      "24/08/20 09:04:58 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Got job 30 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Final stage: ResultStage 34 (parquet at NativeMethodAccessorImpl.java:0)\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Missing parents: List()\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[94] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/08/20 09:04:58 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 103.6 KiB, free 433.8 MiB)\n",
      "24/08/20 09:04:58 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.7 MiB)\n",
      "24/08/20 09:04:58 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.255.255.254:32855 (size: 37.4 KiB, free: 434.2 MiB)\n",
      "24/08/20 09:04:58 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[94] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/08/20 09:04:58 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "24/08/20 09:04:58 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 30) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7846 bytes) \n",
      "24/08/20 09:04:58 INFO Executor: Running task 0.0 in stage 34.0 (TID 30)\n",
      "24/08/20 09:04:58 INFO Executor: Finished task 0.0 in stage 34.0 (TID 30). 3675 bytes result sent to driver\n",
      "24/08/20 09:04:58 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 30) in 17 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "24/08/20 09:04:58 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "24/08/20 09:04:58 INFO DAGScheduler: ResultStage 34 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.042 s\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/08/20 09:04:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "24/08/20 09:04:58 INFO DAGScheduler: Job 30 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.046604 s\n"
     ]
    }
   ],
   "source": [
    "df_produtos = spark.read.parquet(\"gold/produtos_lucros.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
